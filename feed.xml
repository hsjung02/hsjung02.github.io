<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://hsjung02.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://hsjung02.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-04-12T13:40:34+00:00</updated><id>https://hsjung02.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry xml:lang="ko"><title type="html">어학능력</title><link href="https://hsjung02.github.io/blog/2024/languages/" rel="alternate" type="text/html" title="어학능력"/><published>2024-03-18T22:05:42+00:00</published><updated>2024-03-18T22:05:42+00:00</updated><id>https://hsjung02.github.io/blog/2024/languages</id><content type="html" xml:base="https://hsjung02.github.io/blog/2024/languages/"><![CDATA[<h1 id="영어">영어</h1> <h2 id="20200106-toefl-practice-online">[2020.01.06.] TOEFL Practice Online</h2> <p><img src="/assets/img/posts/어학능력/Untitled.png" alt="Untitled"/></p> <p>R 26 / L 25 / S 18 / W 28 // Tot 97</p> <p>대학 입학 전 신입생 영어수업 배치고사를 위해 TPO를 응시하였다. TPO는 TOEFL Practice Online의 약자로, 실제 토플과 완전히 똑같은 구성으로 시험을 친다. 실제 토플보다 점수가 좀 더 잘 나온다는 카더라가 있다. 말하기에서 매우 저조한 성적을 획득하여 보강이 필요할 듯하다.</p> <h2 id="20210829-toeic">[2021.08.29.] TOEIC</h2> <p><img src="/assets/img/posts/어학능력/Untitled%201.png" alt="Untitled" width="500"/></p> <p>LC 480 / RC 440 // Tot 920</p> <p>대학 2학년 때 카투사 지원을 위해 토익을 응시하였다. 카투사는 고득점이 필요 없고 780점만 넘으면 되기 때문에 가벼운 마음으로 치러갔다. 문제가 많아서 좀 힘들었지만 시간이 부족하지는 않았다. 인터넷에 있는 환산표를 보면, 토익 920점이 토플 110점 정도 된다는데 아마 토플을 치면 최대 100점 정도 나올 듯하다. 토익은 상대평가 요소가 있기 때문에 내 원래 실력보다 좀 더 잘 나온 것 같다.</p> <h2 id="20240309-teps">[2024.03.09.] TEPS</h2> <p><img src="/assets/img/posts/어학능력/Untitled%202.png" alt="Untitled"/></p> <p>L 179 / V 38 / G 41 / R 196 // Tot 454</p> <p>토익 유효기간이 만료되어서 영어점수 갱신을 위해 텝스를 쳤다. 사실 토익을 다시 치는게 제일 좋지만(비용 및 난이도 측면에서) 장학금 지원기간 내에 점수가 나오는 시험이 텝스랑 오픽밖에 없어서 텝스를 선택했다. 텝스는 시험 중 시간부족으로 많이 힘들었다. LC는 시간 문제가 없지만, Voca&amp;Grammar와 RC에서는 시간이 많이 부족했다. Grammar는 마지막 두 문제(한 문단에서 문법 오류가 있는 문장 찾아내는 유형)는 손도 못 대고 찍었다. Voca&amp;Grammar에서 시간부족을 겪은 이후, RC에서도 시간부족 문제가 발생할 수 있겠다고 생각했다. 그래서 RC에서는 답이 10초 이내로 떠오르지 않는 경우 과감히 넘어가는 전략을 택했다. 시험시간 1분이 남았을 때 앞에서 넘어간 문제 2개 및 풀지 못한 문제 8문제가 남았어서, 넘어간 문제 2개를 적당히 풀고 마지막 8문제는 a로 밀었다.</p> <p>국가시험 지원 시에 어학성적을 5년까지 인정해준다고 하는데, 전문연 지원에도 해당되면 정말 좋을 것 같다.</p> <p>보카, 그래머 점수가 너무 낮게 나왔다… 공부를 좀 더 열심히 하자!</p> <p>인터넷에 환산표 살펴보니 뉴텝스 454가 토익 920~960에 걸치는 것 같은데, 영어 실력이 횡보하는 것 같다. 공부를 하긴 해야할듯.</p>]]></content><author><name></name></author><category term="[&quot;Personal&quot;]"/><summary type="html"><![CDATA[어학능력 기록]]></summary></entry><entry xml:lang="ko"><title type="html">기어에 대하여</title><link href="https://hsjung02.github.io/blog/2024/Gears/" rel="alternate" type="text/html" title="기어에 대하여"/><published>2024-03-15T00:05:42+00:00</published><updated>2024-03-15T00:05:42+00:00</updated><id>https://hsjung02.github.io/blog/2024/Gears</id><content type="html" xml:base="https://hsjung02.github.io/blog/2024/Gears/"><![CDATA[<h1 id="기어">기어</h1> <p>     </p> <h2 id="기어란">기어란</h2> <blockquote> <p><strong>톱니바퀴</strong> 또는 <strong>기어</strong>(gear, <a href="https://ko.wikipedia.org/wiki/%EB%AC%B8%ED%99%94%EC%96%B4">문화어</a>: 기야)는 톱니의 맞물리는 힘으로 <a href="https://ko.wikipedia.org/wiki/%EB%8F%99%EB%A0%A5">동력</a>을 전달하는 장치이다. 간단한 <a href="https://ko.wikipedia.org/wiki/%EB%8B%A8%EC%88%9C_%EA%B8%B0%EA%B3%84">단순 기계</a>다. -Wikipedia</p> </blockquote> <p>기어란 동력 전달 장치의 일종으로서, 그 중에서도 톱니의 맞물림을 통해 미끄러짐 없는 구름을 구현한 장치이다.</p> <p>기어의 장점으로는 크게 (1) 미끄러짐 없는 구름운동이 가능, (2) 자유로운 가감속이 가능하다는 것이 있다.</p> <h2 id="기어의-종류">기어의 종류</h2> <p>널리 사용하는 기어로는 스퍼 기어(평기어), 헬리컬 기어, 유성 기어, 베벨 기어, 웜 기어 등이 있으며 장단점을 파악하여 필요에 따라 사용하는 것이 유리하다.</p> <p>스퍼 기어는 가장 사용하기 쉽다는 장점이 있다. 스퍼 기어는 평행한 두 축간 동력 전달밖에 하지 못한다.</p> <p>헬리컬 기어는 스퍼 기어보다 소음이 적고 수명이 길다는 장점이 있으나, 가격이 비싸고 에너지 효율이 떨어진다는 단점이 있다.</p> <p align="center"> <img src="/assets/img/posts/Gears/Untitled.png" width="30%"/> </p> <p>헬리컬 기어</p> <p>베벨 기어는 두 기어의 회전축을 교차해 놓은 형상을 가리킨다. 굳이 수직하게 교차할 필요 없이, 다양한 방향으로 조합이 가능하다. 베벨 기어에는 스퍼 기어 및 헬리컬 기어를 사용할 수 있다.</p> <p align="center"> <img src="/assets/img/posts/Gears/Untitled%201.png" width="30%"/> </p> <p>베벨 기어</p> <p>웜 기어는 나선형의 웜과 스퍼(혹은 헬리컬) 기어 형상의 웜 휠을 맞물리게 하여 동력을 전달하는 장치이다. 웜이 회전하면 웜 휠이 돌지만, 웜 휠이 회전해서 웜을 돌릴 수는 없다.</p> <p align="center"> <img src="/assets/img/posts/Gears/Untitled%202.png" width="30%"/> </p> <p>웜 기어</p> <h2 id="fundamental-law-of-gearing">Fundamental law of gearing</h2> <p>기어는 “미끄러짐 없는 구름”을 구현하기 위한 장치인데, 이것은 적합한 설계를 통해서만 가능하다.</p> <p>Fundamental law of gearing은 다음과 같다.</p> <aside> 💡 Angular velocity ratio between gears remains constant through the mesh. </aside> <p>이 말을 다음과 같이 바꿔 쓸 수 있다.</p> <aside> 💡 The common normal at the point of contact between a pair of teeth must always pass through the pitch point. </aside> <p>아래의 조건을 성립하면 위의 조건을 성립한다. 자세한 내용은 <a href="https://medium.com/@learnengineering/gear-types-definition-terms-used-and-the-law-of-gearing-98c7517ef93">Medium 글</a> 섹션 5를 참고.</p> <p>이때 pitch point로부터 기어 중심까지의 거리가 피치원 반지름이 된다. 피치원이란, 기어를 원기둥으로 모델링했을 때 기어의 둘레를 의미한다. 기어와 관련된 몇 가지 파라미터를 살펴보면 다음과 같다.</p> <table> <thead> <tr> <th>명칭</th> <th>잇수(Number of teeth)</th> <th>피치원(Pitch diameter)</th> <th>지름피치(Diametral pitch)</th> <th>원주피치(Circular pitch)</th> <th>모듈(module)</th> </tr> </thead> <tbody> <tr> <td>정의</td> <td>기어의 총 이 개수</td> <td>피치원의 지름</td> <td>피치원 상에서 단위길이당 이 개수</td> <td>피치원 상에서 이웃한 두 이 사이의 거리</td> <td>원주피치 / pi</td> </tr> <tr> <td>식</td> <td>N</td> <td>D</td> <td>P = N/D</td> <td>p = pi D/N</td> <td>m = D/N</td> </tr> </tbody> </table> <p><strong>Fundamental law of gearing을 만족하기 위해서는 P, p, m이 같은 기어들을 사용해야 한다.</strong></p> <h2 id="기어-이tooth-형상">기어 이(tooth) 형상</h2> <p>Fundamental law of gearing을 만족하는 대표적인 이 형상은 involute shape이다. Involute curve는 아래 사진과 같이 줄을 쭉 당겼을 때 만들어지는 곡선이다.</p> <p align="center"> <img src="/assets/img/posts/Gears/Untitled%203.png" width="30%"/> </p> <p>Involute shape 외에도 cycloidal shape을 사용할 수 있다.</p> <h2 id="기어비">기어비</h2> <p>기어비를 적절히 설정하면 원하는 만큼의 감속비를 얻을 수도 있고, 회전력을 증폭할 수도 있다.</p> <p>위에서 모듈이 같은 기어끼리 사용해야 한다고 했는데, 이때 m을 고정하면 D 혹은 N을 자유롭게 조정할 수 있다. 보통은 N을 바꾸는데, 왜냐하면 N이 engineering parameter로서 의미가 있기 때문이다.</p> <p>미끄러짐 없는 구름에서 두 기어가 맞닿는 지점에서의 선속도는 같다. 두 기어를 각각 1, 2라 하면 다음의 식이 성립한다.</p> \[v_1=v_2\] <p>따라서 다음 식도 성립한다.</p> \[\omega_1 \frac {D_1}{2} = \omega_2 \frac {D_2}{2}\] <p>모듈이 같다고 했으므로,</p> \[m_1 = \frac{D_1}{N_1} = \frac{D_2}{N_2} = m_2\] <p>정리하면</p> \[\omega_2 = \frac{N_1}{N_2}\omega_1\] <p>으로 기어 개수의 비(기어비)에 따라 회전속도가 바뀌는 것을 알 수 있다.</p> <p>기어비를 조정하면 회전속도도 바뀌고 동시에 토크도 바뀐다. 에너지 보존 법칙을 생각해보면,</p> \[P_1 = \tau_1 \omega_1 = \tau_2 \omega_2 = P_2\] <p>이므로 다음과 같이 토크가 증폭된다.</p> \[\tau_2 = \frac{N_2}{N_1}\tau_1\] <p>정리하면,</p> \[\omega_2 = \frac{N_1}{N_2}\omega_1\\ \tau_2 = \frac{N_2}{N_1}\tau_1\] <h1 id="유성기어">유성기어</h1> <p>     </p> <h2 id="특징">특징</h2> <p>유성기어(Planetary gear set, Epicyclic gear)는 Sun gear 주변을 Planet gear가 돌고 이것을 Ring gear가 감싸고 있는 형태이다. 유성기어는 구동축과 회전축이 일치한다는 특성을 갖고 있다.</p> <h2 id="기어비-1">기어비</h2> <p>유성기어는 일반적으로 S, P, R 기어 중 하나를 고정시키고 하나를 구동하여 나머지 하나를 회전시킨다. 이때 감속비는 다음의 공식으로 계산할 수 있다.</p> \[\omega_S = -\frac{N_R}{N_S}\omega_R + (1+\frac{N_R}{N_S})\omega_P\] <p>상황에 따라 \(\omega_S=0, \omega_R=0, \omega_P=0\)을 대입하여 계산하면 된다.</p> <h2 id="설계-예시">설계 예시</h2> <p>기어비 10 이상의 기어가 필요해서 만들기로함. 모터와 바퀴 사이에 달아야 하는데, 회전축을 달 공간이 마땅치 않아서 유성기어를 사용하기로 했다.</p> <p>Ring gear가 지면과 접촉하는 바퀴의 역할을 할 것이고, sun gear가 모터와 연결된 구동축이 될 것이기 때문에 planet gear의 회전축을 고정하여야 한다\((\omega_P=0)\). 기어 잇수 및 모듈 선정은 다음의 Mixed integer nonlinear programming 문제가 된다.</p> \[\begin{align*} &amp; \min 1 \\ s.t. \ &amp; \frac{N_R}{N_S} \ge10\\ &amp;N_S, N_P, N_R \ge 17 \\ &amp; N_S, N_P. N_R \in Z^+ \\ &amp; \frac{D_S}{N_S} = \frac{D_P}{N_P} = \frac{D_R}{N_R} = m\\ &amp;D_R = D_S + 2D_P\\ &amp; D_S \ge 8 \\ &amp; D_R \le 130 \\ \end{align*}\] <p>압력각 20도 기준 기어당 잇수가 17개 이상이어야 튼튼하다고 하여서 두 번째 조건을 추가하였고, 아래 두 조건은 각각 구동축 지름과 바퀴 지름을 고려한 조건이다.</p> <p>이 문제는 해가 여러 개 존재할텐데, 손으로 풀어서 찾은 해는 다음과 같다.</p> \[(N_S, N_P, N_R, m) = (18, 99, 216, 0.6)\] <p>이렇게 하면 기어비 12를 달성할 수 있다.</p> <h2 id="제작">제작</h2> <p>Autodesk inventor를 이용해 stl 파일을 제작 후 3D 프린터로 인쇄하였다.</p> <p>인벤터에서 기어를 쉽게 제작하는 방법을 소개하겠다.</p> <p>1) 인벤터에서 새 조립품 문서를 생성한 후, 설계&gt;전동&gt;스퍼 기어 선택</p> <p>2) 설계 안내서에서 자동으로 계산하고 싶은 값 선택(중심 거리로 하는게 편한듯)</p> <p>3) 기어비 입력: 13처럼 넣어줘도 되는데, 잇수를 다 계산해놨으면 216/99처럼 입력해주는게 더 좋음</p> <p>4) Ring gear처럼 내부 기어의 경우 내부 체크박스 선택</p> <p>5) 모듈 값 입력</p> <p>6) 기어1 드롭다운에 “구성요소” 선택</p> <p>7) 이나비 칸에 기어 두께 입력</p> <p>8) 기어2 드롭다운에 “모형 없음” 선택 → 1개의 기어만 생성됨</p> <p>9) 계산 및 확인: 계산 실패 알림이 뜨면 무시하고 승인을 누른다.</p> <p align="center"> <img src="/assets/img/posts/Gears/Untitled%204.png" width="70%"/> </p> <p>10) 생성된 기어 우클릭 후 “톱니 쉐이프 내보내기” 선택 → 새 부품 파일이 생성됨</p> <p>11) 사진과 같이 이 형상이 그려진 것을 확인할 수 있다.</p> <p align="center"> <img src="/assets/img/posts/Gears/Untitled%205.png" width="50%"/> </p> <p align="center"> <img src="/assets/img/posts/Gears/Untitled%206.png" width="50%"/> </p> <p>12) 돌출 컷을 해준다.</p> <p>13) “원형” 기능을 이용하여 돌출을 회전축에 대해 잇수만큼 반복해준다.</p> <p align="center"> <img src="/assets/img/posts/Gears/Untitled%207.png" width="50%"/> </p> <p>14) 완성!</p> <p align="center"> <img src="/assets/img/posts/Gears/Untitled%208.png" width="50%"/> </p> <p>반복해주면 이러한 유성 기어를 제작할 수 있다.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <img src="/assets/img/posts/Gears/Untitled%209.png" width="100%"/> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <video src="/assets/img/posts/Gears/IMG_2461.mp4" class="img-fluid rounded z-depth-1" width="auto" height="auto" controls=""/> </figure> </div> </div> <p>Planet gear의 회전축이 외부 구조물에 의해 고정되어 있기 때문에 sun gear를 돌리면 ring gear가 회전한다.  </p> <p><a href="https://ko.wikipedia.org/wiki/톱니바퀴">톱니바퀴</a></p> <p><a href="https://blog.naver.com/americano20/220509998568">기어 종류 및 특징</a></p> <p><a href="https://kr.misumi-ec.com/tech-info/categories/machine_design/md05/g0085.html">웜기어 선정 포인트 (선정 개요)</a></p>]]></content><author><name></name></author><category term="[&quot;Notes&quot;]"/><category term="Tech"/><summary type="html"><![CDATA[기어 이론 및 설계]]></summary></entry><entry xml:lang="ko"><title type="html">IMU &amp;amp; Filtering</title><link href="https://hsjung02.github.io/blog/2024/IMU&Filtering/" rel="alternate" type="text/html" title="IMU &amp;amp; Filtering"/><published>2024-03-10T00:05:42+00:00</published><updated>2024-03-10T00:05:42+00:00</updated><id>https://hsjung02.github.io/blog/2024/IMU&amp;Filtering</id><content type="html" xml:base="https://hsjung02.github.io/blog/2024/IMU&amp;Filtering/"><![CDATA[<h1 id="imu">IMU</h1> <p>IMU는 관성 측정 장치를 뜻하는 Inertial Measurement Unit 약자이다. IMU는 주로 회전각(기울어짐)을 측정하기 위해 사용하는 장치이다.</p> <h2 id="구성">구성</h2> <p>IMU에는 가속도계와 자이로스코프가 기본적으로 내장되고, 제품에 따라 지자기계가 추가된다. 가속도계와 자이로스코프만을 사용하면 6축 IMU, 지자기계까지 사용하면 9축 IMU가 된다.</p> <p>가속도계는 특정 방향으로의 가속도를 측정하는 장치로, 세 개의 가속도계를 사용하면 3차원 가속도를 측정할 수 있다. 자이로스코프는 특정 방향으로의 각속도를 측정하는 장치로, 세 개의 자이로스코프를 사용하면 3차원 각속도를 측정할 수 있다.</p> <p>IMU를 회전 측정 용도로 사용한다면 결국 3차원 정보만 얻게 되는 것인데, 이를 위해서 6개의 센서가 필요하다는 것이 약간은 이상할 수 있겠다. 하지만 실제로는 IMU가 6차원 정보를 갖고 있고, 이 중 우리가 원하는 3차원 정보만 추출하기 위해서는 6개의 센서가 필요하다고 이해하면 되겠다.</p> <h3 id="가속도계">가속도계</h3> <p>가속도계를 이용해 회전을 측정하는 방법을 알아보자.</p> <p>다음과 같은 spatial frame과 body frame을 고려하자. Spatial frame은 z축이 연직 방향으로 정렬된 좌표계이고, body frame은 현재 IMU 센서의 rotation을 나타낸다. 중력을 제외하고는 IMU에 가해지는 외력이 없다 가정한다면, IMU의 가속도 벡터는 \(\vec g_s = (0 \ 0 \ -g)^T\)가 될 것이다. 가속도 벡터를 \(\{ b \}\)에서 나타내면 \(\vec g _b = R_{bs} \vec g_s\)인데, 이것이 IMU에서 측정한 3차원 가속도 벡터가 될 것이다. 가속도계 정보로부터 \(\vec g_b\)를 알 수 있으므로, \(R_{bs}\)를 유추할 수 있다.</p> <p>Rotation matrix \(R_{bs}\)를 구하기 위해 ZYX Euler angle을 고려하자. \((R, P, Y) = (\alpha, \beta, \gamma)\)를 가정하면</p> \[\begin{align*} R_{sb} &amp; = R_z(\gamma) R_y(\beta) R_x(\alpha) \\ &amp; = \begin{pmatrix} c_\gamma &amp; -s_\gamma &amp; 0 \\ s_\gamma &amp; c_\gamma &amp; 0 \\ 0 &amp; 0 &amp; 1 \end{pmatrix} \begin{pmatrix} c_\beta &amp; 0 &amp; s_\beta \\ 0 &amp; 1 &amp; 0 \\ -s_\beta &amp; 0 &amp; c_\beta \end{pmatrix} \begin{pmatrix} 1 &amp; 0 &amp; 0 \\ 0 &amp; c_\alpha &amp; -s_\alpha \\ 0 &amp; s_\alpha &amp; c_\alpha \end{pmatrix} \\ &amp; = \begin{pmatrix} c_\gamma &amp; -s_\gamma &amp; 0 \\ s_\gamma &amp; c_\gamma &amp; 0 \\ 0 &amp; 0 &amp; 1 \end{pmatrix} \begin{pmatrix} c_\beta &amp; s_\beta s_\alpha &amp; s_\beta c_\alpha \\ 0 &amp; c_\alpha &amp; -s_\alpha \\ -s_\beta &amp; c_\beta s_\alpha &amp; c_\beta c_\alpha \end{pmatrix} \\ &amp; = \begin{pmatrix} c_\gamma c_\beta &amp; c_\gamma s_\beta s_\alpha - s_\gamma c_\alpha &amp; c_\gamma s_\beta c_\alpha + s_\gamma s_\alpha \\ s_\gamma c_\beta &amp; s_\gamma s_\beta s_\alpha + c_\gamma c_\alpha &amp; s_\gamma s_\beta c_\alpha - c_\gamma s_\alpha \\ -s_\beta &amp; c_\beta s_\alpha &amp; c_\beta c_\alpha \end{pmatrix} \end{align*}\] <p>를 구할 수 있다.</p> \[\begin{align*} R_{bs} &amp; = R_{sb}^T \\ &amp; = \begin{pmatrix} c_\gamma c_\beta &amp; c_\gamma s_\beta s_\alpha - s_\gamma c_\alpha &amp; c_\gamma s_\beta c_\alpha + s_\gamma s_\alpha \\ s_\gamma c_\beta &amp; s_\gamma s_\beta s_\alpha + c_\gamma c_\alpha &amp; s_\gamma s_\beta c_\alpha - c_\gamma s_\alpha \\ -s_\beta &amp; c_\beta s_\alpha &amp; c_\beta c_\alpha \end{pmatrix} ^T \\ &amp; = \begin{pmatrix} c_\gamma c_\beta &amp; s_\gamma c_\beta &amp; -s_\beta \\ c_\gamma s_\beta s_\alpha - s_\gamma c_\alpha &amp; s_\gamma s_\beta s_\alpha + c_\gamma c_\alpha &amp; c_\beta s_\alpha \\ c_\gamma s_\beta c_\alpha + s_\gamma s_\alpha &amp; s_\gamma s_\beta c_\alpha - c_\gamma s_\alpha &amp; c_\beta c_\alpha \end{pmatrix} \end{align*}\] <p>이때 \(\vec g_s\)의 \(x, y\) 성분이 0이므로 \(\vec g_b\)는 \(R_{bs}\)의 3열의 상수배가 나오게 된다.</p> \[\begin{align*} \vec g_b &amp; = R_{bs} \vec g_s \\ &amp; = R_{bs} \begin{pmatrix} 0 \\ 0 \\ -g \end{pmatrix} \\ &amp; = r_3 (-g) \\ &amp; = \begin{pmatrix} g s_\beta \\ -g s_\beta s_\alpha \\ -g c_\beta c_\alpha \end{pmatrix} \\ &amp; = \begin{pmatrix} a_x \\ a_y \\ a_z \end{pmatrix} \end{align*}\] <p>따라서 다음의 식을 통해 \(\alpha, \beta\)를 구할 수 있다.</p> \[\begin{align*} \alpha &amp; = \tan^{-1} \left( \frac{a_y}{a_z} \right) \\ \beta &amp; = \tan^{-1} \left( \frac{a_x}{\sqrt{a_y^2 + a_z^2}} \right) \end{align*}\] <p>가속도계를 통해 자세를 측정하는 방법은 세 가지 문제에 직면한다.</p> <ol> <li>중력 외의 외력이 작용할 경우 정확한 측정이 불가능 → 자이로스코프와 센서 퓨전</li> <li>Yaw angle 측정 불가능 → 자이로스코프, 지자기계를 사용하여 측정</li> <li>짐벌락, singularity? (ex. \(c_\beta = 0\)) → 쿼터니언 사용하여 해결</li> </ol> <p>*쿼터니언 간단 설명</p> <p>Quaternion은 수학자 <a href="https://en.wikipedia.org/wiki/William_Rowan_Hamilton">William Hamilton</a>이 발견한 개념으로, 허수단위 \(i\)처럼 동작하는 \(j,k\)의 개념을 추가하여 basis가 4개인 수 체계이다. 우리말로는 4원수라고 한다. 사원수에서는 우리가 사용하는 수 체계에 다음의 조건을 추가하여 사용한다.</p> \[i^2 = j^2 = k^2 = ijk = -i\] <p>Quaternion을 이용해 회전을 나타낼 수 있는데, 이는 rotation matrix 및 exponential coordinate의 개념과 꽤나 유사하다. \(\vec \omega = (\omega_x \ \omega_y \ \omega_z)^T\)에 대해 \(\theta\)만큼의 회전을 나타내기 위해서는 다음과 같은 quaternion \(q\)를 정의한다.</p> \[q = \cos\frac \theta 2 + i \omega_x\sin\frac\theta 2 + j \omega_y\sin\frac\theta 2 + k\omega_z\sin\frac\theta 2\] <p>이후 quaternion product \(\otimes\)를 다음과 같이 정의한다.</p> \[\begin{align*} \mathbf{a} \otimes \mathbf{b} &amp; = [a_1 \ a_2 \ a_3 \ a_4 ] \otimes [b_1 \ b_2 \ b_3 \ b_4 ] \\ &amp; = \begin{bmatrix} a_1b_1 - a_2b_2 - a_3b_3 - a_4b_4 \\ a_1b_2 + a_2b_1 + a_3b_4 - a_4b_3 \\ a_1b_3 - a_2b_4 + a_3b_1 + a_4b_2 \\ a_1b_4 + a_2b_3 - a_3b_2 + a_4b_1 \end{bmatrix} \end{align*}\] <p>Quaternion product는 \(i, j, k\)간의 곱셈을 떠올리면 쉽게 이해할 수 있다.</p> <p>Quaternion을 이용한 회전 연산은 다음과 같이 계산할 수 있다.</p> \[v'= q \otimes v \times q^{-1}\] <p>이때 \(qq^*=1\)이므로 다음과 같이 쓸 수 있다.</p> \[v' = q \otimes v \otimes q^*\] <p>이는 마치 rotation matrix와 같은 작용을 하는데, 실제로 quaternion과 rotation 간의 일대일대응을 할 수 있다. 인터넷에 찾아보면 사람들이 다음의 식을 유도해 놓았다.</p> \[\mathbf{R}(q) = \begin{bmatrix} 2q_1^2 - 1 + 2q_2^2 &amp; 2(q_2q_3+q_1q_4) &amp; 2(q_2q_4 - q_1q_3) \\ 2(q_2q_3 - q_1q_4) &amp; 2q_1^2 - 1 +2q_3^2 &amp; 2(q_3q_4 + q_1q_2) \\ 2(q_2q_4 + q_1q_3) &amp; 2(q_3q_4 - q_1q_2) &amp; 2q_1^2-1+2q_4^2 \end{bmatrix}\] <p>다만 나는 조금 더 간단하게 생각할 수 있다고 생각한다. 두 가지 방법이 있는데, 서로 비슷하다.</p> <p>1) Exponential coordinate</p> <p>\(q\)와 \((\hat\omega,\theta)\)가 일대일대응인데 \(R\)도 \((\hat\omega,\theta)\)와 일대일대응이므로 관계식을 쉽게 찾을 수 있다.</p> <p>2) \(i,j,k\)와 \(\hat x, \hat y, \hat z\)의 대응관계</p> \[R = \text{expm}(\lceil \hat\omega \rceil \theta) = \begin{pmatrix} r_{11} &amp; r_{12} &amp; r_{13} \\ r_{21} &amp; r_{22} &amp; r_{23} \\ r_{31} &amp; r_{32} &amp; r_{33} \end{pmatrix}\] <p>일 때, 다음의 식을 유도할 수 있다.</p> \[q \cdot i \cdot q^* = r_{11}i + r_{21}j + r_{31}k \\ q \cdot j \cdot q^* = r_{12}i + r_{22}j + r_{32}k \\ q \cdot k \cdot q^* = r_{13}i + r_{23}j + r_{33}k \\\] <p>그런데 우리는 다음의 식을 알고 있다.</p> \[R\hat x = r_{11}\hat x + r_{21}\hat y + r_{31}\hat z\\ R\hat y = r_{12}\hat x + r_{22}\hat y + r_{32}\hat z\\ R\hat z = r_{13}\hat x + r_{23}\hat y + r_{33}\hat z\] <p>두 식으로부터 모티브를 얻어서, \(q \otimes v \otimes q^*\)를 matrix form으로 바꿀 수 있을 것이라 생각하였고 결과는 다음과 같다.</p> \[\begin{pmatrix} q_1 &amp; q_2 &amp; q_3 &amp; q_4 \\ q_1 &amp; q_2 &amp; q_3 &amp; q_4 \\ q_1 &amp; q_2 &amp; q_3 &amp; q_4 \\ q_1 &amp; q_2 &amp; q_3 &amp; q_4 \\ \end{pmatrix} \begin{pmatrix} 0 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; v_x &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; v_y &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; v_z \end{pmatrix} \begin{pmatrix} q_1 &amp; q_1 &amp; q_1 &amp; q_1 \\ q_2 &amp; q_2 &amp; q_2 &amp; q_2 \\ q_3 &amp; q_3 &amp; q_3 &amp; q_3 \\ q_4 &amp; q_4 &amp; q_4 &amp; q_4 \end{pmatrix} = \begin{pmatrix} 0 &amp; 0 \\ 0 &amp; R \end{pmatrix} \begin{pmatrix} 0 &amp; 0 &amp; 0 &amp; 0\\ 0 &amp; v &amp; v &amp; v \end{pmatrix}\] <p>조금 더 깔끔하게 정리할 수 있을 것 같은데, 그건 나중에 하자!</p> <h3 id="자이로스코프">자이로스코프</h3> <p>자이로 센서를 이용해 회전을 측정하는 방법을 알아보자.</p> <p>자이로 센서를 이용하면 세 방향으로의 각속도를 측정할 수 있다. 각속도를 알고 있으므로, 이를 적분하여 각변위를 구할 수 있다.</p> \[\begin{align*} \alpha &amp; = \int \omega_x dt \\ \beta &amp; = \int \omega_y dt \\ \gamma &amp; = \int \omega_z dt \end{align*}\] <p>(각속도 벡터가 body frame에서 나타나 있으니까 이것을 spatial frame에서 다시 나타낸 후 적분해야 하는 것 아닌가?)</p> <p>자이로 센서를 통해 자세를 측정하는 방법은 두 가지 문제에 직면한다.</p> <ol> <li>초기 각변위를 알 수 없음 → 0으로 가정 / 보정 / 가속도계와 센서 퓨전</li> <li>적분 오차가 누적되면 long-term 오차 발생 → 가속도계 및 지자기계와 센서 퓨전</li> </ol> <h3 id="지자기계">지자기계</h3> <p>지자기 센서는 자기장의 세기를 측정하는 센서이다. 지구는 거대한 자석이기 때문에, IMU가 북쪽 방향으로 정렬되어 지구의 자기력선과 일치할 때 지자기 센서가 최대값을 측정한다. 따라서 지자기계를 사용하면 yaw 값을 측정할 수 있다.</p> <p>지자기계를 통해 자세를 측정하는 방법은 세 가지 문제에 직면한다.</p> <ol> <li>Roll, pitch 값을 알 수 없음 → 가속도계, 자이로스코프를 통해 측정</li> <li>주변 전기장/자기장에 영항을 받음 → 어쩔 수 없음/보정 필요</li> <li>진북과 자북이 다름 → 위도 정보를 알고 있다면 편각(declination)을 알 수 있으므로 보정 가능</li> </ol> <h2 id="필터">필터</h2> <p>가속도계를 이용한 자세 추정은 중력가속도가 아닌 다른 가속도로 인해 short-term 오차가 발생하고, 자이로 센서를 이용한 자세 추정은 적분 오차로 인한 long-term 오차가 발생하므로 이것을 적절하게 조합하면 오차를 줄일 수 있다는 개념이 바로 센서 퓨전이다.</p> <p>아래 세 개의 필터는 센서 퓨전을 위한 대표적인 알고리즘이다.</p> <h3 id="complementary-filter-상보-필터">Complementary filter (상보 필터)</h3> <p>상보 필터의 식부터 보면 다음과 같다. 자이로 센서를 통해 측정한 각속도를 \(\dot\theta_g\), 가속도계를 통해 측정한 각도를 \(\theta_a\)라 하면 상보 필터를 통해 추정하는 각도는</p> \[\theta_c \leftarrow \alpha\theta_c +\dot\theta_g \Delta t + (1-\alpha)\theta_a, \ \alpha = 1 - \tau \Delta t\] <p>로 나타낼 수 있다. 이때 \(\Delta t\)는 센서들의 sampling time이고 \(\tau\)는 적당한 상수값이다.</p> <p>이 필터가 어떻게 잘 동작할 수 있는지 이해하기 위해서는 LPF와 HPF에 대한 간단한 이해가 필요하다. LPF는 저주파 성분만 통과시키는 필터이고, HPF는 고주파 성분만 통과시키는 필터이다. 이를 시간 영역에서 해석해보면 LPF를 적용하면 long term 신호만 통과하고 HPF를 적용하면 short term 신호만 통과한다. 가속도계의 신호는 short term 오차가 있으므로 LPF를 적용하여 long term 신호만 사용하고, 자이로 센서의 신호는 long term 오차가 있으므로 HPF를 적용하여 short term 신호만 사용하자.</p> <p>1차 LPF와 HPF의 전달함수는 다음과 같이 나타낼 수 있다.</p> \[\begin{align*} LPF(s) &amp; = \frac{\tau}{s+\tau} \\ HPF(s) &amp; = \frac{s}{s+\tau} \end{align*}\] <p>이때 \(\tau\)는 cutoff frequency이다.</p> \[\begin{align*} \theta_c(s) &amp; = HPF(s)\theta_g(s) + LPF(s)\theta_a(s) \\ &amp; = \frac{s}{s+\tau} \frac 1 s \omega_g(s) + \frac{\tau}{s+\tau}\theta_a(s) \\ &amp; = \frac{1}{s+\tau}\omega_g(s) +\frac{\tau}{s+\tau}\theta_a(s) \\ (s+\tau)\theta_c(s) &amp; = \omega_g(s) + \tau\theta_a(s) \\ \dot \theta_c(t) + \tau\theta_c(t) &amp; = \omega_g(t) + \tau\theta_a(t) \\ \end{align*}\] <p>마지막 식을 이산 시간 영역으로 옮겨와 정리하면,</p> \[\begin{align*} \frac{\theta_{c, k+1} - \theta_{c,k}}{\Delta t} + \tau\theta_{c,k} &amp; = \omega_{g,k} + \tau\theta_{a,k} \\ \theta_{c,k+1} &amp; = (1-\tau\Delta t)\theta_{c,k} + \omega_{g,k} \Delta t + \tau\Delta t\theta_{a,k} \\ \theta_{c,k+1} &amp; = \alpha \theta_{c,k} + \omega_{g,k} \Delta t + (1-\alpha)\theta_{a,k} \\ \end{align*}\] <p>를 구할 수 있다.</p> <p>(다른 버전)</p> <p>혹자는</p> \[\theta_c = \alpha \theta_g + (1-\alpha)\theta_a, \ \alpha = \frac{\tau}{\tau+\Delta t}\] <p>를 사용하기도 한다. 이것도 잠시 살펴보면</p> \[LPF(s) X(s) = \bar X(s)\] <p>라 하면, 위와 비슷한 방법으로</p> \[\bar x _k = \frac{\tau}{\tau + \Delta t}\bar x _{k-1} + \frac{\Delta t}{\tau+\Delta t}x_k\] <p>를 구할 수 있다.</p> <p>HPF도 비슷하게</p> \[\bar y_k = \frac{\tau}{\tau + \Delta t}(\bar y_{k-1} + y_k - y_{k-1})\] <p>로 쓸 수 있다. 이때 이전 timestep의 값을 쓰지 않고 현재 timestep의 값만 사용한다고 생각하면</p> \[\begin{align*} \bar x_k &amp; = \frac{\Delta t}{\tau + \Delta t}x_k \\ \bar y_k &amp; = \frac{\tau}{\tau + \Delta t} y_k \end{align*}\] <p>이므로 \(\theta_c = \bar \theta_g + \bar \theta_a\)로 쓰고 \(\bar \theta_g = \theta_c + \dot\theta_g \Delta t\)로 쓰면</p> \[\theta_c \leftarrow \alpha (\theta_c + \omega_g \Delta t) + (1-\alpha)\theta_a\] <p>로 구할 수 있다.</p> <p>뭐가 더 좋을지는 잘 모르겠다.</p> <h3 id="kalman-filter-칼만-필터">Kalman filter (칼만 필터)</h3> <p><img src="/assets/img/posts/IMU/Untitled.png" alt="Untitled"/></p> <p>이 부분은 칼만 필터 공부 후 다시 작성할 예정</p> <h3 id="madgwick-filter-매드그윅-필터">Madgwick filter (매드그윅 필터)</h3> <p>Madgwick filter도 complementary filter와 비슷한 형태인데, 조금 더 복잡하다.</p> <p>Madgwick filter의 유도는 다음의 식을 어떻게 더 잘 쓸 수 있을까라는 고민을 해결하는 과정이다.</p> \[q_{\text{est},t} = \gamma_t q_{\text{acc}, t} + (1-\gamma_t)q_{\text{gyro},t}\] <p>(1) \(q_{\text{acc}, t}\)를 어떻게 계산할 것인가</p> <p>(2) \(q_{\text{gyro},t}\)를 어떻게 계산할 것인가</p> <p>(3) Weight \(\gamma_t\)를 어떻게 설정할 것인가</p> <p>(1) \(q_{\text{acc}, t}\)를 어떻게 계산할 것인가</p> <p>Accelerometer 측정 결과를 이용해 자세를 추정하는 방법으로, Madgwick에서는 optimization을 사용하였다. 위에서 설명한 방법과 거의 동일하지만, analytic하게 풀지 않고 optimization을 쓰는 이유는 quaternion을 complete하게 구하기 위해서이다. 위에서 설명한 방법에서는 yaw를 알 수 없었기 때문에 quaternion 또한 unique, complete하게 계산되지 않는다. 대신 optimization을 쓰면 하나의 quaternion을 구할 수 있다. Formulation은 다음과 같다.</p> \[\underset{\hat q}{\text{argmin }} \hat q^{-1} \otimes \hat g \otimes \hat q - \hat s\] <p>이때 \(\hat q\)는 spatial frame에 대한 IMU의 자세, \(\hat g\)는 gravity acceleration, \(\hat s\)는 가속도계를 통해 측정한 가속도 벡터이다.</p> <p>이 최적화 문제는 gradient descent를 통해 풀 수 있는데, 이때 gradient를 jacobian을 이용해 analytic하게 구했기 때문에 속도가 빠르다는 것이 Madgwick의 주장이다.</p> <p>Update rule은 아래와 같다.</p> \[q_{k+1} = \hat q_k - \mu \frac{\nabla f}{||\nabla f||}, \nabla f = J^T f\\ \mu_t = \alpha ||\dot q||\] <p>Analytic jacobian을 계산하는 과정은 <a href="https://x-io.co.uk/downloads/madgwick_internal_report.pdf">원문</a>을 참고.</p> <p>(2) \(q_{\text{gyro},t}\)를 어떻게 계산할 것인가</p> <p>다음의 공식을 이용한다.</p> \[\mathbf{\omega} = [0 \ \omega_x \ \omega_y \ \omega_z] \\ \dot q = \frac 1 2 \hat q \otimes \mathbf{\omega}\] <p>이를 이용하면 update rule은</p> \[\dot q _t = \frac 1 2 \hat q_{\text{est}, t-1} \otimes \omega_t \\ q_{\omega, t} = \hat q_{\text{est}, t-1} + \dot q_{\omega, t} \Delta t\] <p>(3) Weight \(\gamma_t\)를 어떻게 설정할 것인가</p> <p>여기서도 재미있는 트릭이 나온다. Madgwick 씨는 \(\gamma_t\)의 optimal value가 \(q_\text{acc}\)의 weighted convergence와 \(q_\text{gyro}\)의 weighted divergence가 같아지게 하는 값이라고 주장하고, 다음과 같이 계산하였다.</p> \[(1-\gamma_t)\beta = \gamma_t \frac{\mu_t}{\Delta t} \\ \gamma_t = \frac{\beta}{\frac{\mu_t}{\Delta t}+\beta}\] <p>이때 \(\beta\)가 filter gain으로써 tuning parameter가 되는 듯하다.</p> <p>Gradient descent를 할 때 사용하는 \(\alpha\)를 매우 크게 설정하면 \(\mu_t\)가 매우 큰 값이 되므로 다음의 두 근사가 유효하다.</p> \[q_\text{acc} \approx -\mu_t \frac{\nabla f}{||\nabla f||} \\ \gamma_t \approx \frac{\beta \Delta t}{\mu_t}\] <p>이 근사를 적용하면</p> \[q_{\text{est},t} = \hat q _{\text{est}, t-1} + \dot q _{\text{est},t}\Delta t \\ \dot q_{\text{est}, t} = \dot q_{\text{gyro}, t} - \beta \dot{\hat q}_{\epsilon, t}\\ \dot{\hat q}_{\epsilon, t} = \frac{\nabla f}{||\nabla f||}\] <p>로 필터가 단순해진다.</p> <p>필터의 다이어그램은 아래와 같다.</p> <p><img src="/assets/img/posts/IMU/Untitled%201.png" alt="Untitled"/></p> <p>소스코드는 아래 파일을 참고.</p> <p><a href="/assets/img/posts/IMU/GY80BasicAHRS.ino">GY80BasicAHRS.ino</a></p> <h2 id="참고자료">참고자료</h2> <p><a href="https://velog.io/@717lumos/Sensor-IMU의-개념-및-활용법">[IMU] IMU의 개념 및 활용법</a></p> <p><a href="https://en.wikipedia.org/wiki/Euler_angles">Euler angles</a></p> <p><a href="https://m.blog.naver.com/ysahn2k/221385063966">[MEMS] 상보필터 (Complementary Filter)</a></p> <p><a href="https://sites.google.com/a/kookmin.ac.kr/mr-h/kudos/robot-study/complementary-filter-sangbo-pilteo">Mr.H - Complementary Filter(상보 필터)</a></p> <p><a href="https://ddangeun.tistory.com/137">1차 Low-Pass Filter(저주파 통과필터), High-Pass Filter(고주파 통과 필터) 구현하기, 코드</a></p> <p><a href="https://wsstudynote.tistory.com/7">[우수학부생] Kalman Filter 을 이용한 자세 추정 및 모션 캡처를 이용한 실험 결과</a></p> <p><a href="https://x-io.co.uk/downloads/madgwick_internal_report.pdf"></a></p>]]></content><author><name></name></author><category term="[&quot;Notes&quot;]"/><category term="Tech"/><summary type="html"><![CDATA[IMU 간단한 이론 및 사용법]]></summary></entry><entry xml:lang="ko"><title type="html">시스템설계를 마치며</title><link href="https://hsjung02.github.io/blog/2023/ME-Capstone-Review/" rel="alternate" type="text/html" title="시스템설계를 마치며"/><published>2023-12-28T22:05:42+00:00</published><updated>2023-12-28T22:05:42+00:00</updated><id>https://hsjung02.github.io/blog/2023/ME-Capstone-Review</id><content type="html" xml:base="https://hsjung02.github.io/blog/2023/ME-Capstone-Review/"><![CDATA[<p>시스템설계: 캡스톤디자인. 기계과 졸업과제. 학부에서 넘어야 할 마지막 산이었다. 졸업과제를 매우 중요하게 생각하는 사람으로서… 종합설계랑 비슷하게 시스템설계도 잘하고 싶었다. 사실 종설을 무사히 마친 나는 무서울 게 없었다.</p> <p><br/></p> <h2 id="사건의-발단">사건의 발단</h2> <p>팀은 무난하게 꾸려졌다. 여름방학에 연구실에 같이 있던 창균, 자영, 그리고 창균에게 같이 하자고 했던 정민, 그리고 어떤 경위인지는 아직도 모르겠으나 수업 끝나고 교수님께 질문하고 돌아오니 합류해있던 기성이형까지.</p> <p>시스템설계는 여름방학 때 해야하는 게 없어서 좀 편했는데, 보니까 중간고사 전까지 주제 정하고 중간고사 끝나고 만들어야 하는 일정이라 많이 타이트해 보였다. 이래저래 위태위태해 보이는 설계가 시작되었다.</p> <p><br/></p> <h2 id="전개">전개</h2> <p>일단 주제를 정해야 했다. 사실 처음에는 연참 때 하던걸 그대로 가져갈까 생각했다. 여름방학에 연참하던게 작년부터 거의 1년 동안 하던거고, 결과도 좀 괜찮게 나와있어서 그대로 만들기만 하면 그럴싸해 보일 것 같았다. 하지만 마음 한켠에서 날먹하면 안될 것 같다는 생각이 들어서… 새롭게 시작하기로 했다. 팀별 주제를 정하기에 앞서, 모든 학생이 각자가 생각한 주제를 발표해야 했다. 내가 생각했던 주제는 ‘과속방지턱’이었다. 근데 이제 움직이는. 동기는 단순했는데, 현재 사용되는 정적 과속방지턱은 싸고 튼튼하다는 장점이 있지만 한 가지 치명적인 기능적 문제가 있다. 그것은 바로, 아무리 천천히 달려도 차에 충격이 가해진다는 것이다. 과속방지턱의 설치 목적이 차량의 주행 속도를 규정 속도 미만으로 제한하는 것임을 생각하면, 규정 속도 미만으로 주행하는 저속 차량에게도 패널티를 주는 것이 큰 문제임을 알 수 있다. 이 문제를 어떻게 해결할 수 있을까 생각하다가, 지금처럼 정적 구조물을 설치해서는 해결할 수 없다는 결론에 이르렀다. 그렇다면 과속방지턱을 움직여야 한다는 것인데, 어떻게 하면 잘 움직일 수 있지? 생각하다가 안전벨트가 떠올랐다. 자동차의 안전벨트는 유사시 탑승자를 보호하기 위해 세게 잡아당기면 잠금이 걸린다. 하지만 천천히 잡아당기면 잘 나온다. 아마 초등학교나 중학교에서 이것이 관성의 원리를 이용한 것이라고 배웠던 것 같다. 아무튼 이렇게 훌륭한 speed-selective한 시스템을 찾았으니, 잘 엮으면 할 수 있을 것 같았다. 어떻게 할지는 모르겠지만.</p> <p>각자 주제를 발표한 이후에 팀 내에서 주제를 정해서 교수님께 말씀드리거나, 제시된 주제 중에서 교수님이 지정해주셨다. 우리 팀은 제시된 주제가 다 괜찮아서 고민이 되었고, 그냥 교수님께서 정해주시는 걸로 하기로 했다. 운 좋게도 내 주제가 선정되었다.</p> <p>아이디어를 구체화해야 했는데, 처음에 생각했던 것은 차량이 방지턱을 밟고 지나가면 차량의 속도에 따라 방지턱이 움직이는 속도가 달라질 것이니 빠르게 움직이면 안전벨트 시스템을 이용해 움직임을 제한하자는 방식이었다. 나는 이 방식이 매우 직관적이어서 좋다고 생각했는데, 발전시키다 보니 차량의 속도와 방지턱의 속도 사이 관계를 분석하는 것이 매우 어려웠고 더 큰 문제는 방지턱의 속도가 차량의 속도뿐만 아니라 질량 등에도 영향을 받는다는 것이었다. 이러면 방지턱의 동작이 차량의 속도에만 영향을 받지 않으므로 무거운 차는 천천히 지나가도 패널티를 받고 가벼운 차는 빠르게 가도 패널티를 받지 않는 등 시스템이 목적과 다르게 작동할 가능성이 있어서 아이디어는 폐기되었다.</p> <p>그 다음으로 제시된 아이디어는 지면에 접하는 롤러를 지하에 설치하고 차량이 그 위를 지나가면서 마찰에 의해 롤러를 굴리는 방식이었다. 이 경우 미끄러짐 없는 구름을 가정하면 롤러의 회전선속도가 차량의 속도와 일치한다. 또한 시스템의 입력 저항이 작다고 가정하면 시스템과의 접촉으로 인해 차량이 받는 충격도 거의 없기 때문에 괜찮은 방식이었다. 이 아이디어를 채택했다.</p> <p>이제 해야 할 것은 (1) 아이디어 발전, (2) 제작 및 실험이었다.</p> <p>자동차의 이동에 의해 발생하는 롤러의 회전을 이용해 방지턱을 움직이기로 했고, 이를 위해 롤러와 방지턱 사이에 gear train을 설치했다. Gear train의 한 축에는 안전벨트를 연결해서 speed-selective한 동작을 구현했다. 그러면 gear motion이 있는 경우에 방지턱이 내려오고, 없는 경우에 정지해 있는 메카니즘을 만들어야 했다. 이것은 toggle position을 응용해서 만들었다. 보통 toggle position은 4-bar linkage에서 발생하는데 우리는 5-bar linkage로 만들었다. 근데 사실상 4-bar처럼 작동하기는 한다. Toggle position에 의해 방지턱을 위에서 아무리 눌러도 움직이지 않고, 액추에이터가 작동해야만 링크들이 움직이면서 방지턱이 내려올 수 있다.</p> <p>방지턱 설계도 거의 예술로 했는데, 움직이는 동안 지면과 닿지 않아야 하고 다 내려왔을 때는 평지가 되어야 했다. 부채꼴과 직각삼각형을 합쳐서 해결했다.</p> <p>와! 이제 진짜 만들기만 하면 된다.</p> <p><br/></p> <h2 id="위기">위기</h2> <p>작은 모형으로 제작하기로 했고, 나무나 아크릴을 가공해서 상자를 만들어 구현하기로 했다. 일단 안전벨트 모듈을 분석하기로 했다. 관련 특허를 찾아봤는데 부품이 20여개나 되었다. 이걸 직접 만들 자신도 없었고, 만들 필요도 없다고 생각했다. 이미 똑똑한 박사님들이 다 만들어 놓으셨는데 우리가 굳이 또 만들 필요가 있을까?라는 생각에 인근 폐차장에 방문했다. 근데 흔히 찾는 부품도 아니고 이것을 캐려면 분해를 많이 해야 해서 구하기가 쉽지 않았다. 몇 군데를 돌아다닌 결과 안전벨트 모듈을 뜯어주시겠다는 사장님이 계셨다. 심지어 아카데믹 라이센스로 해주셨다(무료라는 뜻). 흥해공고 다니냐고 물어보시길래 포항공대 다닌다고 했다. 우리가 그렇게 어려보였나?ㅎㅎ 아무튼 모듈을 무려 2개나 획득했다. 가장 어려울 것 같았던 안전벨트 부분이 쉽게 해결되니 남은 일은 일사천리로 끝날 듯 했다.</p> <p>기계공학과 학생이 역학을 못하는 죄로 벌을 받았다. 일단 다 만들었는데, 만들고 나니까 차가 지나가도 롤러를 굴리지를 못했다. 처음에는 제작을 잘못해서 안굴러가는 줄 알고, 굴릴 수 있는 방법을 고민했다. 그러다가 나온 결론: 이거 안굴러가는게 맞는듯. 차의 질량이 크고, 타이어에 변형이 일어날 수 있어서 차량 바퀴와 롤러 사이에 line contact이 생기면 굴러가는데, 그렇지 않아서 point contact이면 굴러가지 않는다는 것이었다. 우리는 진짜 좌절했다. 이대로 끝나는건가? 우리 졸업할 수 있나? 새벽 4시에 학관 편의점에서 컵라면을 먹으며, 실패 보고서는 어떻게 쓸지에 대해 생각하는 우리는 너무 처량했다.</p> <p>사실 원래 만들려고 했던 것은 다 만들어서 이대로 때려칠까 했었는데, 여기서 발상의 전환이 필요했다. ‘원래 만들려고 했던 것은 다 만들었는데’→이제 데모만 잘 하면 된다는 뜻이었다. 그러니까 우리가 만든 시스템은 우리가 의도했던대로 잘 굴러가는데, real world와 prototype간의 차이로 인해 구현하지 못한 부분이 생긴 것이니 이 부분만 어떻게 잘 처리를 해서 발표를 하자…라는 얘기였다.</p> <p>여기서부터는 현실성을 하나도 생각하지 않고 어떻게 롤러를 굴릴 수 있을지만 생각했다. 차에 실을 달아서 축을 돌리자, 차가 바닥에 있는 막대를 밀고 가게 하자, 차 바퀴를 타이밍풀리로 만들고 바닥에 타이밍벨트를 깔자… 등등 별의별 아이디어가 다 나왔는데, 결국 채택한 것은 ‘차량의 속도를 측정해서 그 속도에 비례하게 모터를 돌려주자’였다. 아마 아두이노로. 사실 이 방법이 우리가 생각한 것들 중에서 제일 쉽고 강력한 방법이었다. 근데 하기 싫었다. 우리가 처음 시작할 때 우리의 시스템에 전자부품을 넣지 말자고 했었는데, 이 방법을 쓰면 패배한 기분이 들 것 같아서 정말 하기 싫었다. 근데 이것보다 좋은 방법을 생각할 수 없었다. 그래서 해야만 했다.</p> <p>위의 문제가 발생한게 발표 3주 전이고, 아두이노를 시작한게 2주 전이니까 정확히 2주 동안 아두이노에 매달렸다. 진짜 별의별 문제가 다 발생했다. 노이즈 때문에 속도 측정이 잘 안되는 문제, 초음파 센서가 너무 광각이라 생기는 문제, 초음파 센서가 귀신을 보는 문제, 모터 토크가 부족해서 롤러를 못 굴리는 문제, 단차, 유격, 서보모터 토크 부족 등등 지금도 생각만 하면 짜증부터 나는 문제들을 2주 동안 붙잡고 있었다. 마지막에는 결국 기막히게 해결해서 다행이다.</p> <p><br/></p> <h2 id="결말">결말</h2> <p>꼬박 2주 동안 밤을 새고, 발표날까지도 밤을 샌 우리는 결국 우리가 원하던 데모를 구현하는 데에 성공했다. 최종발표가 아침 9시였는데 아침 6시 정도에 성공을 했으니 3시간이 남았던 셈이다. 달리 말하면 지금까지 반나절만 허투루 썼어도 성공하지 못했을 거라는 말… 하여튼 성공적으로 데모 영상을 찍고, 발표 준비를 하고, 발표를 하고, 현장 데모까지 성공했다.</p> <p>12월에는 다른 과목들이 많이 바쁘지 않아서 거의 한 달을 온전히 설계에 썼는데, 하나의 프로젝트에 이렇게 많은 시간과 노력을 들인 것은 진짜 처음인 것 같다. 비단 프로젝트뿐이 아니라 어떤 대상에 이 정도로 몰두한 적이 없었는데, 끝까지 파고들면서 정말 많이 배울 수 있었다. 단순히 제작이라는 과정에 필요한 기술, 노하우 같은 것들뿐만 아니라 끈기, 문제 해결, 협동을 배울 수 있었고. 무엇보다 중요한, “재밌었다”. 와 대학원 가면 이걸 하루종일 할 수 있다고? 정말 기대된다ㅎ.ㅎ.ㅎ</p> <p>무슨 말을 해야할까.</p> <p>수고했다!</p> <p>마침.</p>]]></content><author><name></name></author><category term="[&quot;Personal&quot;]"/><summary type="html"><![CDATA[시스템설계를 마치며]]></summary></entry><entry xml:lang="ko"><title type="html">종합설계과제를 마치며</title><link href="https://hsjung02.github.io/blog/2023/EE-Capstone-Review/" rel="alternate" type="text/html" title="종합설계과제를 마치며"/><published>2023-06-22T00:05:42+00:00</published><updated>2023-06-22T00:05:42+00:00</updated><id>https://hsjung02.github.io/blog/2023/EE-Capstone-Review</id><content type="html" xml:base="https://hsjung02.github.io/blog/2023/EE-Capstone-Review/"><![CDATA[<p>1년간 정말 열심히 했던 종합설계과제가 끝이 나고, 뭔가 시원섭섭한 마음에 그간 어디에서도 할 수 없었던 이야기들을 남기려고 한다. 24개의 중간보고서, 12번의 지도교수 면담, 5번의 발표, 1번의 학회발표에는 담을 수 없었던 그런 얘기들…을 까먹기 전에 몇 자 적어보았다.</p> <p><br/></p> <h2 id="사건의-발단">사건의 발단</h2> <p>종합설계를 3학년 2학기에 하게 된 것은 매우 우연찮은 일이었다. 내가 전자과 복전을 결정한 것이 2학년 2학기의 일이고, 3학년 1학기에는 공부하느라 바쁘다는 핑계로 미래의 일은 별로 생각을 안했다(하지만 3초에 20학점 들었으니까 바빴다고 해도 괜찮지 않을까!). 종합설계는 1년짜리이고, 기계과 설계도 해야 하니까 3학년 2학기에 기계과 설계를 하든 전자과 설계를 하든 무언가는 시작했어야 하는 상황이었으나 일단은 별 생각이 없었다. 그런데 3학년 1학기에 김지우와 청암에서 전자회로 공부를 같이 하고 기숙사로 돌아가던 중에 설계는 어떻게 할 거냐는 이야기를 나눴고, 그러다가 2학기에 설계를 같이 하자고 얘기가 되었다.</p> <p>그렇게 수강신청을 했다.</p> <p><br/></p> <h2 id="전개">전개</h2> <p>그런데 이놈의 종합설계는 요구하는 것이 너무 많았다. 제일 킹받는 점은 여름방학에 연구계획서를 쓰라고 하는 점이었다. 그럴거면 방학 때 수강신청을 시켜서 학점을 주든가! 연구실에 앉아 있었는데 김상우 교수님으로부터 메일이 한 통 왔다. 8월 중순까지 조편성을 완료하고 지도교수님을 정해 연락하라나 뭐라나… 그리고 8월 말일까지 연구계획서를 제출하라나 뭐라나… 주제 선정이 딱 봐도 선착순인 것 같으니까 그날 저녁에 바로 김지우를 만나서 학식 먹으면서 주제 이야기를 했다. 근데 듣자하니 본인이 지금 연참을 하고있는 강석형 교수님께서 설계과제 주제를 주셨다는 것이다. 사실 나는 당연히 로봇이나 제어 쪽으로 하고 싶었는데 갑자기 반도체 해야 할 것 같은 느낌이 와서 조금 불안했다. 근데 뭐,, 나는 반도체 하기 싫다 말하기도 그렇고 그때도 별 생각이 없었던 나는 알겠다고 했고, 그렇게 강석형 교수님과의 면담이 추진되었다.</p> <p>강석형 교수님을 만나러 가는 길에는 비가 내렸다. 나는 그때 효자에서 자취를 하고 있었는데 비도 오고 늦은 거 같아서 택시를 타고 엘지동까지 갔던 기억이 난다. 그때 내가 레퍼런스를 읽고 갔었는지 안 읽고 갔었는지 기억은 잘 안나는데 그 자리에서 1시간 정도 교수님과 면담을 했다. RL-based chip placement automation. 이것이 우리에게 주어진 주제였다. 몇 개 선택할 수 있었는데 이게 제일 재미있어 보였다. 레퍼런스 논문은 <a href="https://www.nature.com/articles/s41586-021-03544-w">A graph placement methodology for fast chip design | Nature</a>이다.</p> <p>사실 뭐랄까 강 교수님은 종합설계를 좀 가볍게 보시는거 같았다. 면담 할 때에도 이렇게 진행할 계획이다 말씀드리면 이거는 뭐 구현 정도만 하면 성공적이라 볼 수 있다 / 너무 어렵게 잡았다가 연구 주제를 바꾸는 팀도 간혹 있다 등 욕심부리지 말라는 식으로 말씀하셔서 기분이 좀 묘했다. 결론적으로는 일년동안 교수님 지도사항 중에서 방향성이나 범위에 관한 부분은 거의 안들었고, 테크니컬한 부분이나 데모 등에서 말씀해주신 부분만 수용한 것 같다.</p> <p>연구계획서를 쓰기 위해서 공부를 좀 해야했다. 일단 반도체 및 설계 분야도 공부를 해야했고, 강화학습도 공부해야 했고 강화학습 기반 반도체 설계도 공부해야 했다. 어찌저찌 해서 연구계획서를 썼다.</p> <p>웃긴 점은 개강 3주차에 주제를 엎었다는 것이다. 원래는 연구 목표를 두 가지로 잡았다. 첫째는 standard cell placement에 사용하는 standard cell placer에 따른 학습 성능 비교, 둘째는 보상함수 설정에 따른 학습 성능 비교였다. 그런데 연구계획서 쓰면서 생각을 열심히 하지 않은 것일까, standard cell placer와 보상함수가 연관이 있을 것이라는 생각이 불현듯 들었다. 예를 들어 method A와 B가 있는데, method A는 wirelength를 줄이는 대신 congestion이 좀 높고 B는 wirelength가 좀 큰 대신 congestion이 작으면 A로 학습을 할 때는 보상함수에서 congestion weight를 좀 높이고 B로 학습을 할 때는 congestion weight를 줄여야 하지 않을까… 라는 생각이 든 것이다. 그래서 좀 생각을 해보고 연구의 방향성을 바꾸게 되었다.</p> <p>이후로는 실험 계획을 세웠다. 실험 환경만 잘 구성하면 실험은 일사천리로 진행될 것 같았다. 일단 실험 진행은 standard cell placer를 여러 개 구현한 다음, 각 방법에 대해서 congestion weight를 바꿔가며 모델 성능을 측정하고 분석을 하는 것이었다. 이것을 하기 위해서는 학습을 진행할 수 있고 standard cell placer를 마음대로 바꿀 수 있는 환경을 구축해야 했다. 조사를 하다가 구글에서 코드를 공개한 것을 발견했다. 나는 코드를 발견하고 너무 기뻤다. 이 코드를 잘 쓰면 속전속결로 진행할 수 있을 것 같았다. 하지만 코드는 문제가 많았다. 코드가 문제인건지 내가 문제인건지는 잘 모르겠지만, reproduction이 잘 안됐다. 그래서 어쩔 수 없이 직접 구현해야 한다는 결론에 도달했다.</p> <p><br/></p> <h2 id="위기">위기</h2> <p>구현은 만만치 않았다(않아 보였다). Chip placement 환경을 구성해야 했고, 강화학습을 구현해야 했다. Chip placement 환경은 먼저 lefdef 파일을 파싱해서 회로를 재구성하는 과정이 필요했고, 이후 placement 과정에서 macro placement와 standard cell placement를 각각 구현해야 했다. 강화학습의 경우 tf-agent나 stable baselines 같은 라이브러리를 사용하려고 했는데, 순탄치가 않았다. Macro placement를 할 때 state에 따라 가능한 action이 달라진다. 가장자리에 배치하면 안되고, 소자 겹침이 존재하는 위치에 배치하면 안되고, 밀도가 너무 높게 배치하면 안된다. 이것을 배제하고 학습 및 inference를 진행하는 것을 라이브러리를 통해서는 구현할 수가 없었다. 그래서 어쩔 수 없이 강화학습 부분도 직접 구현해야만 했다. 사실 이때까지도 강화학습에 대해 잘 몰랐기 때문에 깃헙에 떠돌아다니는 코드를 복붙해서 사용했다.</p> <p>어찌저찌해서 코드를 완성하고, 학습을 했다. 이때가 2학기 중간고사 기간이었는데 지금 돌아보면 정말 난장판이었지만 그때는 뭔가 된다는 사실만으로 되게 기뻤던 것 같다. 2학기 나머지 기간에는 구현을 보완하는 것에 힘썼다. 일단 테스트케이스를 더 간단한 것을 썼고, 그 다음으로는 standard cell placer를 구현하려고 했다. Standard cell placer로 뭘 쓸까 고민하다가 Aplace를 골랐다. Aplace가 좀 오래된 방법이긴 하지만 쓸만해보였다. 그런데 이걸 한달동안 구현을 못해서 결국 빈 공간에 좌상단부터 채워넣는 greedy placement를 채택한게 너무 슬프다.</p> <p>겨울방학에는 KCS에 가서 발표를 했는데, 이때도 정말 우당탕탕이었다. 학회 등록은 했는데 잘 곳이 없어서 다른 애들 방에 낑겨서 같이 자고, 포스터는 전날에 개판으로 만들어서 선배들한테 한번 깨진 후 밤새서 만들어서 당일 인쇄해서 가져가고… 좀 힘들긴 했지만 좋은 경험을 했다고 생각한다.</p> <p>1학기에는 구현을 좀 제대로 해보려고 노력했다. 사실 지금도 뭔가 되는거 같아 보이기는 했지만 내가 짠 코드이기에 나는 알고 있었다. 코드가 정말 개판이라는 것을. 피처 추출도 제대로 안했고, standard cell placer도 이상하고, PPO 코드도 뭔가 어정쩡해 보이고… 고칠 부분이 많았다. 하나씩 차례대로 해보기로 했다. 일단 피처 추출은 PyTorch geometric을 써보려고 했는데, 뭔가 문제가 많이 생겼다. 통합하는 과정에서 문제가 생겨서 pytorch geometric을 쓸 수가 없었다. GNN에 특화된 라이브러리라고 해서 기대를 했는데 아쉬웠다. Standard cell placer의 경우 김지우가 구현을 했다. eplace를 잘 변형해서 force-directed method를 만들었는데, 생각보다 잘 만들어서 좀 놀랐다. 잘 동작해서 너무 다행이었다. 그리고 마지막으로 stable baselines3의 PPO 코드를 도입했다. 이건 불가능할 줄 알았는데 됐다. 사실 이걸 하면서 내가 레퍼런스 조사가 부족했나 싶기도 하면서 레퍼런스 조사의 중요성을 깨닫게 되었다. MaskablePPO라고 불가능한 action을 제외하고 training 및 inference를 하는 알고리즘이 2022년 10월 정도에 발표되었던 것이다. 그리고 언제인지는 모르겠지만 stable baselines3 bleeding edge 버전에 MaskablePPO가 구현이 되어있었다. 그래서 이걸 쓰기로 결정했고, 구현했던 코드를 stable baselines3에 맞추어 수정하는 작업에 돌입했다. Sb3는 pytorch 기반 라이브러리이다. 예전에 tf-agent를 써볼까 생각하면서 tf format에 맞춰 작업할 때가 있었는데, tf보다 pytorch 생태계에 맞추는게 좀 더 쉬웠다. 이래서 다들 pytorch로 넘어오는 건가 싶었다. Environment 포맷 맞추고 나서는 neural network를 수정했다. Feature extractor도 GNN 써서 만들고, policynet이랑 valuenet도 sb3 포맷 맞춰서 다시 만들었다. Feature extractor 만들면서 공부를 진짜 많이 했다. GNN, attention 등 최신 신경망을 많이 공부했는데, 이 과정에서 딥러닝에 대한 이해도 좀 는 것 같고 코딩 실력도 좀 는 것 같다. 원래도 코딩을 못한다고 생각하지는 않았는데, 예전에 하던 코딩은 그냥 내가 생각한 것을 어떻게든 내 스타일로 만들어내는 코딩이고 이번에 한 코딩은 제공되는 라이브러리를 분석하고 그거에 맞추어서 새로운 코드를 짜는 코딩이었다. 이런 식의 코딩은 거의 처음 해보는데, 꽤 재미있었고 많은 것을 배운 느낌이다. 아무튼 그래서 결국에는 됐다.</p> <p><br/></p> <h2 id="결말">결말</h2> <p>되긴 됐는데, 문제는 거기서 멈췄다는 것이다. 12주차인가 13주차 이후로 최종발표 때까지 우리는 아무것도 안했다. 못한건지 안한건지는 모르겠는데 일단 나는 그때 너무 바빴다. 최종발표회 날에 시험이 있었으니 말 다했지… 실험하는 데에도 시간이 그렇게 많이 걸릴 줄은 몰랐는데, 학습 한번 하는데 하룻밤을 꼬박 새야 할 줄은 몰랐다. 서버에서 돌려도 gpu로 가속할 수 있는 부분은 학습 과정이지, environment에서 시간이 많이 드는 것은 가속을 할 수가 없었다. 그래서 포스터에는 원래 계획했던 피겨 및 내용보다 적게 들어가서 너무 아쉬웠다.</p> <p>포스터 발표는 그럭저럭 했는데, 김상우 교수님의 코멘트를 듣고 아 했다. 너희가 찾은 이 30이란 값이 좋다는 것을 어떻게 보일거냐? 나는 레퍼런스에서 domain adaptation이 잘 된다길래 그런갑다 하고 살았는데 그걸 확인해볼 생각을 못했다. 포스터 발표 이후 최종보고서 제출까지 일주일의 기한이 있었기에, 그동안에 실험을 더 돌렸다. 원래 ispd18test3에서 학습을 해서 실험을 했는데, test8에서도 학습을 해보고 test3에서 학습한 모델을 test8에 적용도 해봤다. 실험을 돌려놓고 김지우와 의견차가 있었다. 결과를 예측하면서, 김지우는 엣지 개수가 optimal weight에 영향을 줄 것이라고 생각했는데 내가 생각하기에는 아니었다. Wirelength와 congestion이 모두 edge 개수에 비례하기 때문에 edge 개수가 많아지면 W와 C가 모두 증가하고, edge가 적어지면 W와 C 모두 감소하니까 결국 그것들의 비율인 weight lambda는 scale이 일정하게 유지될 것이었다. 실험 결과도 내 예상과 같았다. 많은 벤치에서 lambda=30이 좋은 값이었다. 사실 이때 정말 다행이라고 생각했다.</p> <p>사실 종설2는 꾸준히 하지를 못해서 성적을 기대하지는 않았는데 에이플을 받아서 정말 기뻤다. 나는 예전부터 졸업과제가 정말 중요하다고 생각해왔다. 한 사람의 대학생활을 평가하는 지표로 성적을 볼 수도 있지만, 졸업과제는 이 사람이 해당 전공에 대한 얼마나 깊은 이해를 하는지를 반영하는 것이기에 졸업과제를 잘 해내는 것 또한 정말 중요하다고 생각한다. 그런만큼 종합설계과제1,2에서 모두 A+를 받아낸 것이 너무 자랑스럽고 뿌듯하다. 단지 종합설계과제를 잘 끝낸 것 뿐만 아니라 그 과정에서 많은 것을 배울 수 있었기에 결과가 더욱 값진 것 같다.</p> <p>쓰다보니 정말 주저리주저리 쓰게 되었는데, 나중에 이 글에 다시 돌아왔을 때 어떤 기분이 들지 정말 궁금하다.</p> <p>2023년 6월 19일 새벽 1시, 마침.</p>]]></content><author><name></name></author><category term="[&quot;Personal&quot;]"/><summary type="html"><![CDATA[종합설계과제를 마치며]]></summary></entry><entry xml:lang="ko"><title type="html">Machine Learning Basic</title><link href="https://hsjung02.github.io/blog/2023/Machine-Learning-Basic/" rel="alternate" type="text/html" title="Machine Learning Basic"/><published>2023-06-21T00:05:42+00:00</published><updated>2023-06-21T00:05:42+00:00</updated><id>https://hsjung02.github.io/blog/2023/Machine-Learning-Basic</id><content type="html" xml:base="https://hsjung02.github.io/blog/2023/Machine-Learning-Basic/"><![CDATA[<h1 id="linear-algebra">Linear algebra</h1> <h2 id="matrix-and-linear-transformation">Matrix and Linear transformation</h2> <p>Matrix는 사실 linear transformation이다.</p> <h2 id="projection">Projection</h2> <p>Projection은 \(P^2=P\)를 만족하는 linear transformation을 의미한다. Vector \(Y\)로의 projection은 \(P=\frac{YY^T}{Y^TY}\)로 나타낼 수 있다.</p> \[pf\rangle W=w\hat{Y}=w\frac{Y}{||Y||} \\w=||X||\cos\theta=||X||\frac{X\cdot Y}{||X||||Y||}=\frac{X\cdot Y}{||Y||}\\ W=w\hat{Y}=\frac{X\cdot Y}{||Y||}\frac{Y}{||Y||}=\frac{X^TY}{Y^TY}Y=\frac{\langle X,Y \rangle}{\langle Y,Y \rangle}Y=Y\frac{Y^TX}{Y^TY}=\frac{YY^T}{Y^TY}X=PX\] <h2 id="least-norm-solution">Least norm solution</h2> <p>Under-determined linear system \(AX=B\) 가 주어졌을 때, \(||X||^2\) 을 최소화하는 \(X^*=(A^TA)^{-1}A^TB\) 로 구할 수 있다.</p> \[pf\rangle A\perp(AX^*-B)\\A^T(AX^*-B)=0\\A^TAX^*=A^TB\\X^*=(A^TA)^{-1}A^TB\] <p>Proof using Lagrange multipliers</p> \[pf\rangle L(x,\lambda)=x^Tx+\lambda^T(Ax-y)\\\nabla_xL=2x+A^T\lambda=0, \nabla_\lambda L=Ax-y=0\\x=-\frac{A^T\lambda}{2}, \lambda=-2(AA^T)^{-1}y\\x=A^T(AA^T)^{-1}y\] <h1 id="optimization">Optimization</h1> <h2 id="optimization-1">Optimization</h2> <p>Optimization에는 3가지 요소가 존재한다.</p> <ol> <li>Objective function</li> <li>Decision variable</li> <li>Constraints</li> </ol> <p>Constraints를 만족하면서 objective function을 최대화/최소화하는 decision variable을 찾는 과정이 최적화이다.</p> <h2 id="convex-problem--convex-optimization">Convex problem &amp; Convex optimization</h2> <h3 id="convex-problem">Convex problem</h3> <p>Convex function: \(\forall x, y\in \mathbb{R}^n \ and \ \theta\in[0,1], f(\theta x+(1-\theta)y)\le\theta f(x)+(1-\theta)f(y)\)</p> <p>Convex set: \(\forall x, y \in C \ and \ \theta\in[0,1], \theta x+ (1-\theta)y\in C\)</p> <p>In convex problems, all local minimums are global minimums.</p> <h3 id="convex-optimization">Convex optimization</h3> <p>Any location where \(f'(x)=0\) is a flat point in the function, and a global minimum for convex problems.</p> <p>This argument also holds for multivariate function, and in this case we evaluate gradient of f, \(\nabla f\) instead of derivative.</p> <p>Then, how can we find the gradient of f? There are two solutions. Analytical solution and iterative solution.</p> <h2 id="matrix-derivatives">Matrix derivatives</h2> \[\nabla (Ax) = A^T\\ \nabla(x^TA)=A \\ \nabla(x^Tx)=2x \\ \nabla(x^TAx)=Ax+A^Tx\] <p>Examples</p> <ul> <li>Affine function \(g(x)=a^Tx+b\): \(\nabla g(x)=a, \nabla^2 g(x)=0\)</li> <li>Quadratic function \(g(x)=x^TPx+q^tX+r, P=P^T\): \(\nabla g(x)=2Px+q, \nabla^2 g(x)=2P\)</li> <li>L2 norm \(g(x)=||Ax-b||^2=x^TA^TAx-2b^TAx+b^Tb\): \(\nabla g(x)=2A^TAx-2A^Tb, \nabla^2 g(x)=2A^TA\)</li> </ul> <h2 id="iterative-method">Iterative method</h2> <p>In iterative method(or gradient descent), we iteratively update x as \(x \leftarrow x-\alpha\nabla_x f(x)\). Here, \(\alpha\) is step size. By iteratively updating x with negative gradient direction, we can reach to minimum.</p> <p>How to set step size? Step size should not be too small, but not too big as well. \(\alpha\) should satisfy: \(f(x_{i+1})-f(x_i)=\nabla f(x_i)\times(-\alpha_i \nabla f(x_i))\)</p> <h1 id="regression">Regression</h1> <h2 id="regression-1">Regression?</h2> <p>Finding the best function to describe given data (x, y) points.</p> <p>Regression is an optimization problem.</p> \[\min_\theta \sum_{i=1}^m(\hat{y}_i-y_i)^2 \\ s.t. \ \hat{y}_i=\theta x_i\] <h2 id="linear-regression">Linear regression</h2> <p>In linear regression, we find \(\theta_0, \theta_1\) where \(\hat{y}_i=\theta_0+\theta_1 x\) and \(\sum (\hat{y}_i-y_i)^2\) is minimized.</p> <p>There are two methods: linear algebra and gradient descent.</p> <h3 id="solve-using-linear-algebra">Solve using linear algebra</h3> <p>\(\theta=(A^TA)^{-1}A^Ty\) where \(A=\begin{pmatrix}1 &amp; x_1 \\\ 1 &amp; x_2 \\\ \vdots &amp; \vdots \\\ 1 &amp; x_n\end{pmatrix}\)</p> <h3 id="solve-using-gradient-descent">Solve using gradient descent</h3> \[f=(A\theta-y)^T(A\theta-y)=\theta^TA^TA\theta-\theta^TA^Ty-y^TA\theta+y^Ty\] \[\nabla f=A^TA\theta+A^TA\theta-A^Ty-A^Ty=2(A^TA\theta-A^Ty)\] \[\theta \leftarrow \theta-\alpha\nabla f\] <h3 id="multivariate-linear-regression">Multivariate linear regression</h3> <p>Formulation as follows:</p> \[\hat{y}_i=\theta_0+\theta_1x_1+\theta_2x_2\] \[\Phi=\begin{pmatrix}1 &amp; x_{1,1} &amp; x_{1,2}\\\ 1 &amp; x_{2,1} &amp; x_{2,2} \\\ \vdots &amp; \vdots &amp; \vdots \\\ 1 &amp; x_{m,1} &amp; x_{m,2}\end{pmatrix}\] \[\theta^*=(\Phi^T\Phi)^{-1}\Phi^Ty\] <h2 id="nonlinear-regression">Nonlinear regression</h2> <p>We can set nonlinear model. This is called nonlinear regression. However, nonlinear regression can be solved just the same as linear regression.</p> <p>There are two methods to solve nonlinear regression. Method 1 is to construct explicit feature vectors. Method 2 is to construct implicit feature vectors.</p> <h3 id="explicit-feature-vectors---polynomial-features">Explicit feature vectors - Polynomial features</h3> <p>Sup. model is \(y=\theta_0 + \theta_1x + \theta_2 x^2\). It looks like nonlinear, but it is a linear regression problem. We can set \(\Phi=\begin{pmatrix}1 &amp; x_1 &amp; x_1^2\\\ 1 &amp; x_2 &amp; x_2^2 \\\ \vdots &amp; \vdots &amp; \vdots \\\ 1 &amp; x_m &amp; x_m^2\end{pmatrix}\) and \(\hat{y}=\Phi\theta\). We can solve by \(\theta^*=(\Phi^T\Phi)^{-1}\Phi^Ty\)</p> <h3 id="explicit-feature-vectors---rbf-features">Explicit feature vectors - RBF features</h3> <p>RBF stands for Radial Basis Function. Define as: \(b_i(x)=\exp(-\frac{||x-\mu_i||^2}{2\sigma^2})\) and \(\hat{y}=\theta_0+\theta_1b_1(x)+\cdots+\theta_nb_n(x)\).</p> <h3 id="implicit-feature-vectors---kernel-trick">Implicit feature vectors - Kernel trick</h3> <p>Classification에서 자세히 다루겠다!</p> <h3 id="avoid-overfitting">Avoid overfitting</h3> <p>We can try three methods to avoid overfitting.</p> <p>First is to use less expensive features. For example, we can use lower degree polynomial, or we can use fewer RBF basis, or we can use larger RBF bandwidth.</p> <p>Second is to keep the magnitude of the parameter small. In many cases, overfitting is associated to large parameter value. This is implemented by adding \(||\theta||\) to constraint or to objective function. In this case, \(J=||\theta X-Y||^2+\lambda||\theta||^2\) and solution \(\theta^*=(X^TX+\lambda I)^{-1}X^Ty\).</p> <p>Third is to use L1 norm. Using L1 norm can be effective when outliers exist. since is more robust and insensitive to outliers. Using L1 norm is called LASSO(Least Absolute Shrinkage and Selection Operator). Using L2 norm is called ridge.</p> <h2 id="k-nearest-neighbor-regression">k-Nearest Neighbor regression</h2> <p>k-Nearest Neighbor (kNN) is a supervised and non-parametric method used for regression and classification. In kNN regression, when new point \(x_{new}\) is given, we make prediction \(y=avg(y|x\in N(x_{new}))\) where \(N(x_{new})\) is kNN of \(x_{new}\).</p> <h1 id="classification">Classification</h1> <h2 id="classification-1">Classification</h2> <p>In classification problem, output y is a discrete value. A classification model determines which class a new input should fall into.</p> <h2 id="perceptron">Perceptron</h2> <h3 id="concept">Concept</h3> <p>When linearly separable datas are given, we can use a perceptron. Perceptron describes a hyperplane which separates data into two classes. Hyperplane is defined by an outward pointing normal vector, \(\omega\), which is orthogonal to any vector on the hyperplane.</p> <h3 id="distance-related-to-perceptron">Distance related to perceptron</h3> <p>Consider a line \(g(x)=\omega_0+\omega^Tx=0\) . We can evaluate distance from a line for any vector \(x\). For any vector \(x\) , \(x=x_\perp+r\frac{\omega}{||\omega||}\) . Here \(r=d+h\) where \(d=-\frac{\omega_0}{||\omega||}\) is the distance from the origin to the line and \(h\) is the distance from the line to vector \(x\) . Then \(g(x)=\omega_0+\omega^Tx=\omega_0+r||\omega||=h||\omega||\) and \(h=\frac{g(x)}{||\omega||}\).</p> <h3 id="perceptron-algorithm">Perceptron Algorithm</h3> <p>As shown above, \(\omega\) is really important in perceptron. Then, how can we find \(\omega\) that well separates given data? We can apply the “Perceptron Algorithm”.</p> <aside> 💡 1. Randomly assign $$\omega$$ 2. One iteration of the PLA(Perceptron Learning Algorithm) $$\omega \leftarrow\omega +yx$$ where $$(x, y)$$ is a misclassified training point 3. At iteration $$i=1,2,3,\cdots,$$ pick a misclassified point from dataset 4. Run a PLA iteration on it </aside> <h2 id="non-separable-problem">Non-Separable problem</h2> <p>In real world, there are noise or outliers that makes a linearly non-separable case. In this case, we can apply three methods for classification. Those are using slack variables, SVM, and kernels.</p> <h2 id="relax-constraints-using-slack-variables">Relax constraints using slack variables</h2> <p>This method is used when there are some outliers. In this case, we allow outliers to be misclassified. However, we want to minimize the misclassified cases. Formulations are as follows:</p> \[\min \sum_{i=1}^Nu_i+\sum_{i=1}^Mv_i\\ s.t. \begin{cases}\omega^Tx^{(i)}\ge1-u_i &amp; (i=1,2,\cdots,N)\\\omega^Tx^{(N+i)}\le-(1-v_i) &amp; (i=1,2,\cdots,M)\\u\ge0\\v\ge0\end{cases}\] <h2 id="support-vector-machine">Support Vector Machine</h2> <p>We can improve above method using linear programming. The idea is that large margin(distance) leads to good generalization on the test data. In SVM, margin is defined as \(\mathrm{margin}=\frac{2}{||\omega||}\) (refer to the distance part). Maximizing margin means minimizing \(||\omega||\) , which is the closest samples from the decision line. We try to maximize minimum distance. Formulations are as follows:</p> \[\min ||\omega||+\gamma(u+v) \\s.t. \ \begin{cases}X_1\omega\ge1-u\\X_0\omega\le-(1-v)\\u\ge0\\v\ge0\end{cases}\] <h2 id="kernels">Kernels</h2> <p>If we do not want to allow misclassfications, or datas are non-linearly separable, we can use kernels. Kernel is a mapping of data to higher dimensions. For example, \(x=\begin{pmatrix}x_1 \\ x_2\end{pmatrix}\) can be expressed as \(z=\phi(x)=\begin{pmatrix}1 \\ x_1^2\\ x_1x_2\\ x_2^2\end{pmatrix}\).</p> <h2 id="logistic-regression">Logistic regression</h2> <p>In logistic regression, we consider distances from decision boundary to all data points. In SVM, we considered distances from decision boundary to two closest data points. Objective function to minimize is the multiplication of all distances. Here we use the technique of using sigmoid function for mapping, so the objective function becomes \(L(\omega)=\prod_{i=1}^nP(y^{(i)}|x^{(i);}\omega)=\prod_{i=1}^n(h_\omega(x^{(i)}))^{y^{(i)}}(1-h_\omega(x^{(i)}))^{1-y^{(i)}}\) . Using log likelihood, \(l(\omega)=\log L(\omega)=\sum_{i=1}^ny^{(i)}\log h_\omega(x^{(i)})+(1-y^{(i)})\log(1-h_\omega(x^{(i)}))\) and \(\hat{\omega}=\argmax_\omega l(\omega)\)</p> <h2 id="k-nearest-neighbor-classification">k-Nearest Neighbor classification</h2> <p>k-Nearest Neighbor (kNN) is a supervised and non-parametric method used for regression and classification. In kNN classification, when new point \(x_{new}\) is given, we make prediction \(y=maxlen(y|x\in N(x_{new}))\) where \(N(x_{new})\) is kNN of \(x_{new}\) .</p> <h1 id="k-means-clustering-algorithm">K-Means: Clustering algorithm</h1> <p>In clustering problem, it is important to catch similarities between samples. We need to make high within-cluster similarity and low inter-cluster similarity.</p> <p>K-Means is an itertive algorithm for clustering. K-Means algorithm is as follows:</p> <aside> ❔ init: randomly initialize cluster centeres do: 1. Cluster assignment for every points, find the nearest cluster center and assign the point to that cluster 2. Move centers move center to the mean of all points in the cluster for each clusters. </aside> <p>When using K-Means algorithm, we need to decide how many clusters we will use. For this, we need to gradually increase the number of clusters and find the elbow points.</p> <p>There are some limitations of k-means. First, it works well only for rounded shaped, equal size clusters. It works bad for non-convex clusters or clusters with different densities.</p> <h1 id="dimension-reduction">Dimension reduction</h1> <h2 id="principal-component-analysis">Principal Component Analysis</h2> <p>In PCA, we remove redundant features using highly correlated data. Let’s first talk about correlation.</p> <h3 id="correlation-and-covariance-matrix">Correlation and Covariance matrix</h3> <p>Variance tells how much the data is spread and covariance tells how two variables are spread. Easily speaking, covariance matrix</p> \[\sum=\begin{pmatrix}E(X_1-\mu_1)(X_1-\mu_1) &amp; E(X_1-\mu_1)(X_2-\mu_2) &amp; \cdots &amp; E(X_1-\mu_1)(X_n-\mu_n) \\\ \vdots &amp; \ddots &amp; \ddots &amp; \vdots \\\ E(X_n-\mu_n)(X_1-\mu_1) &amp; E(X_n-\mu_n)(X_2-\mu_2) &amp; \cdots &amp; E(X_n-\mu_n)(X_n-\mu_n)\end{pmatrix}\] <p>The goal of PCA is to find the direction that maximizes the variance and it can be done by doing eigenalanysis of covariance.</p> \[\begin{align*} (\mathrm{variance \ of \ projected \ data}) &amp;= \frac{1}{m}\sum_{i=1}^m(u^Tx_i)^2\\ &amp;=\frac{1}{m}\sum_{i=1}^m(x_i^Tu)^2\\ &amp;=\frac{1}{m}\sum_{i=1}^mu^Tx_ix_i^Tu\\ &amp;=u^T(\frac{1}{m}\sum_{i=1}^mx_ix_i^T)u\\ &amp;=u^TSu \end{align*}\] \[\max_u u^TSu\\ s.t.\ u^Tu=1\\ \to u^TSu=u^T\lambda u=\lambda\\ \therefore \max\lambda\] <p>PCA can be done by SVD of data matrix X: \(S=\frac{1}{m}X^TX=(\frac{X}{\sqrt{m}})^T(\frac{X}{\sqrt{m}})=A^TA=(U\sum V^T)^T(U\sum V^T)=V\Lambda V^T\). To find \(V\), just do SVD of \(X\).</p> <h2 id="fisher-discriminant-analysis">Fisher Discriminant Analysis</h2> <p>FDA is dimension reduction for labeled data. The goal is to maximize separation between classes while minimizing variance in each class.</p> \[\max_\omega\frac{(\mu_0^T\omega-\mu_1^T\omega)^2}{n_0\omega^TS_0\omega+n_1\omega^TS_1\omega}=\max_\omega\frac{(m^T\omega)^2}{\omega^T(n_0S_0+n_1S_1)\omega}\] <p>Let \(n_0S_0+n_1S_1=\sum=R^TR\) and \(u=R\omega\).</p> <p>\(J(u)=\frac{(m^TR^{-1}u)^2}{\omega^TR^TR\omega}=\frac{((R^{-T}m)^Tu)^2}{u^Tu}=((R^{-T}m)^T\frac{u}{||u||})^2\) is maximum when \(u\parallel R^{-T}m, \therefore u=\alpha R^{-T}m \to \omega=\alpha R^{-1}R^{-T}m=\alpha(n_0S_0+n_1S_1)^{-1}(\mu_0-\mu_1)\)</p>]]></content><author><name></name></author><category term="[&quot;Notes&quot;]"/><category term="Artificial Intelligence"/><summary type="html"><![CDATA[다양한 머신러닝 기법에 대하여]]></summary></entry><entry xml:lang="ko"><title type="html">Modern Control Theory</title><link href="https://hsjung02.github.io/blog/2023/Modern-Control-Theory/" rel="alternate" type="text/html" title="Modern Control Theory"/><published>2023-06-21T00:05:42+00:00</published><updated>2023-06-21T00:05:42+00:00</updated><id>https://hsjung02.github.io/blog/2023/Modern-Control-Theory</id><content type="html" xml:base="https://hsjung02.github.io/blog/2023/Modern-Control-Theory/"><![CDATA[<h1 id="linear-algebra-review">Linear algebra review</h1> <h2 id="rank-of-a-matrix">Rank of a matrix</h2> <p>The ranks of a matrix A is the maximal number of linearly independent cloumns of A. It is denoted by rank(A).</p> <h3 id="properties-of-rank">Properties of rank</h3> <ul> <li>Interchange of two rows (or columns) does not alter the value of the rank. Addition of a multiple of a row (or column) to another row (or column) does not alter the value of the rank</li> <li>Multiplication of a row (or column) by a nonzezro constant c does not alter the value of the rank</li> <li> \[rank(A)=rank(A^T)\] </li> <li>When A is an n*m matrix, \(rank(A)\le min(n,m)\)</li> <li> \[rank(AB) \le min(rank(A), rank(B))\] </li> </ul> <h2 id="determinant">Determinant</h2> <p>A determinant is a scalar and is defined for a square matrix.</p> <table> <tbody> <tr> <td>The determinant of a n*n matrix A is denoted by</td> <td>A</td> <td>.</td> </tr> </tbody> </table> <table> <tbody> <tr> <td>A</td> <td>is defined as:</td> </tr> </tbody> </table> \[|A| = \sum_{j=1}^n (-1)^{i+j}a_{ij}M_{ij}\] <h3 id="properties-of-determinant">Properties of determinant</h3> <ul> <li>Interchange of two rows (or columns) multiplies the value of the determinant by -1</li> <li>Addition of a multiple of a row (or column) to another row (or column) does not alter the value of the determinant</li> <li>Multiplication of a row (or column) by a constant c multiplies the value of the determinant by c</li> <li> <table> <tbody> <tr> <td>When A and B are n*n matrices,</td> <td>AB</td> <td>=</td> <td>A</td> <td> </td> <td>B</td> </tr> </tbody> </table> </li> <li> <table> <tbody> <tr> <td>When A is an n*n matrix, \(rank(A)=n\) iff</td> <td>A</td> <td>\(\not=0\)</td> </tr> </tbody> </table> </li> </ul> <h2 id="inverse-matrix">Inverse matrix</h2> <p>The inverse of an n*n matrix A is denoted by \(A^{-1}\) and is an n *n matrix such that \(AA^{-1}=A^{-1}A=I\)</p> <p>If A has an inverse, the inverse is unique</p> <p>If A has an inverse, then A is called a nonsingular matrix</p> <p>The inverse of a nonsingular matrix A can be given by \(A^{-1}=\frac{1}{|A|}adj(A)=\frac{1}{|A|}C^T(A)\)</p> <h3 id="propreties-of-an-inverse-matrix">Propreties of an inverse matrix</h3> <ul> <li> <table> <tbody> <tr> <td>The inverse of an n*n matrix A existss iff $$</td> <td>A</td> <td>\not=0 $$</td> </tr> </tbody> </table> </li> <li>If A and B are nonsingular, \((AB)^{-1}=B^{-1}A^{-1}\)</li> <li>If A is a nonsingular matrix and \(\alpha\) is a scalar, \((\alpha A)^{-1}=A^{-1}/\alpha\)</li> <li>If A is a nonsingular matrix, \(\text{det} (A^{-1})=1/\text{det}(A)\)</li> </ul> <h2 id="eigenvalues-and-eigenvectors">Eigenvalues and Eigenvectors</h2> <p>For a given n*n matrix A, if there existss a scalar \(\lambda\) and a nonzero vector \(v\) s.t. \(Av = \lambda v\) then \(v\) is called an eigenvector of A corresponding to the eigenvalue \(\lambda\)</p> <h3 id="properties-of-eigenvalues">Properties of eigenvalues</h3> <ul> <li>The eigenvalues of a square matrix A are the roots of the characteristic equation \(\mathrm{det}(sI-A)=0\)</li> <li> <table> <tbody> <tr> <td>When A is an n*n matrix and has the eigenvalues \(\lambda_1, \cdots, \lambda_n\), $$</td> <td>A</td> <td>=\lambda_1\lambda_2\cdots\lambda_n $$</td> </tr> </tbody> </table> </li> </ul> <h2 id="summary-of-determinant-inverse-matrix-and-eigenvalue">Summary of determinant, inverse matrix and eigenvalue</h2> <p>The followings are equivalent:</p> <p>(a) \(A\) is nonsingular</p> <table> <tbody> <tr> <td>(b) $$</td> <td>A</td> <td>\not=0 $$</td> </tr> </tbody> </table> <p>(c) \(rank(A)=n\)</p> <p>(d) 0 is not an eigenvalue of \(A\)</p> <h2 id="quadratic-form">Quadratic form</h2> <p>A quadratic form is a sum of n^2 terms.</p> \[x^TAx = \sum_{i=1}^n\sum_{j=1}^n a_{ij}x_ix_j\] <h3 id="positive-definite-matrix">Positive definite matrix</h3> <p>A symmetric matrix A is said to be positive definite if \(x^TAx&gt;0 \ (\forall x\not=0)\)</p> <p>A symmetric matrix A is said to be semi-positive definite if \(x^TAx\ge0 \ (\forall x\not=0)\)</p> <p>A is a positive definite matrix iff all eigenvalues of A positive</p> <p>A is a semi-positive definite matrix iff all eigenvalues of A nonnegative</p> <p>Q is a positive definite matrix iff there existss a nonsingular matrix \(H\) s.t. \(Q=H^TH\)</p> <h3 id="singular-values">Singular values</h3> <p>Singular values of \(A\) is defined as square root of eigenvalues of \(A^TA\)</p> <p>Eigenvalues of \(A^TA\) are ensured to be positive real values since \(A^TA\) is a positive definite matrix</p> <h2 id="cayley-hamilton-theorem">Cayley-Hamilton theorem</h2> <p>For an n*n matrix A whose characteristic equation is given by \(a(s)=s^n+a_1s^{n-1}+a_2s^{n-2}+\cdots+a_{n-1}s+a_n=0\) the following holds: \(a(A)=A^n+a_1A^{n-1}+a_2A^{n-2}+\cdots+a_{n-1}A+a_nI=0\)</p> <h2 id="diagonalizable-matrix--jordan-canonical-form">Diagonalizable matrix &amp; Jordan canonical form</h2> <p>A square matrix is called diagonalizable if the matrix is similar to a diagnoal matrix.</p> \[\Lambda=P^{-1}AP\] <p>An n*n matrix A is diagonalizable iff A has n linearly independent eigenvectors.</p> <p>If a square matrix A has distinct eigenvalues, A is diagonalizable</p> <p>If a matrix is not diagonalizable, we can pseudo-diagonalize the matrix using Jordan canonical form.</p> <p>\(J=P^{-1}AP\) and \(J\) consists of many Jordan blocks.</p> <p>DEF&gt; Geometric and Algebraic multiplicities</p> <p>Geometric multiplicity: \(rank(A-\lambda_iI)=n-\kappa_i\)</p> <p>Algebraic multiplicity: \(\mathrm{det}(sI-A)=\prod_{i=1}^l(s-\lambda_i)^{n_i}, n_i=n_{i1}+\cdots+n_{i\kappa_i}\)</p> <p>For an eigenvalue \(\lambda_i\), there are \(\kappa_i\) Jordan blocks which have \(\lambda_i\) as diagonal elements and each Jordan block has size of \(n_{ip}\times n_{ip}\)</p> <h1 id="state-space-representation">State-Space representation</h1> <h2 id="state-space-representation-1">State-Space representation</h2> <p>State-Space representation은 input-output relation을 나타내기 위해 하나의 state equation과 하나의 output equation을 이용하는 방법이다.</p> \[\begin{cases}\frac{dx(t)}{dt}=A(t)x(t)+B(t)u(t) \\ y(t)=C(t)x(t)+D(t)u(t)\end{cases}\] <p>state equation이 없으면 ⇒ memoryless system</p> <p>A, B, C, D가 time-variant ⇒ LTV system</p> <p>A, B, C, D가 constant ⇒ LTI system</p> <p>State-Space represenation을 이용하면 signal을 time domain에서 다룰 수 있다. nonzero initial condition을 다룰 수 있고, system의 transient response를 다룰 수 있다.</p> <h2 id="transfer-function-and-state-space-representation">Transfer function and State-Space representation</h2> <p>We can convert between transfer function and State-space representation</p> <h3 id="transfer-function-to-state-space-represenation">Transfer function to State-Space represenation</h3> <p>Method 1: Controllable canonical form</p> <p>Given \(G(s)=\frac{Y(s)}{U(s)}\frac{b_{n-1}s^{n-1}+\cdots+b_1s+b_0}{s^n+a_{n-1}s^{n-1}+\cdots+a_1s+a_0}+d\), let \(X(s)=\frac{1}{s^n+a_{n-1}s^{n-1}+\cdots+a_1s+a_0}U(s)\) then \(Y(s)=(b_{n-1}s^{n-1}+\cdots+b_1s+b_0)X(s)+dU(s)\).</p> <p>We get \(y=b_0x + b_1\frac{dx}{dt}+\cdots+b_{n-1}\frac{d^{n-1}x}{dt^{n-1}}+du\) (output equation) and \(\frac{d^nx}{dt^n}=-a_0x-a_1\frac{dx}{dt}-\cdots-a_{n-1}\frac{d^{n-1}x}{dt^{n-1}}+u\)(state equation)</p> <p>Method 2: Observable canonical form</p> <p>Given \(G(s)=\frac{Y(s)}{U(s)}\frac{b_{n-1}s^{n-1}+\cdots+b_1s+b_0}{s^n+a_{n-1}s^{n-1}+\cdots+a_1s+a_0}+d\), consider \(G_0(s)=G(s)-d\)</p> \[Y(s)=G_0(s)U(s)\rightarrow s^nY(s)+\cdots+a_sY(s)=b_{n-1}s^{n-1}U(s)+\cdots+b_0U(s)\rightarrow a_0y-b_0u+\frac{d}{dt}(a_1y-b_1u+\frac{d}{dt}(\cdots+\frac{d}{dt})a_{n-1}y-b_{n-1}u+\frac{dy}{dt})=0\] <p>By recursively defining \(x_i\) so that \(a_{i-1}y-b_{i-1}u+\frac{dx_i}{dt}=x_{i-1}\), we get</p> \[\frac{d}{dt}\begin{pmatrix} x_1\\ \vdots \\ x_n\end{pmatrix}=\begin{pmatrix} 0 &amp; 0 &amp; \cdots &amp; 0 &amp;-a_0 \\1 &amp; 0 &amp; \cdots &amp; 0 &amp; -a_1 \\ 0 &amp; \ddots &amp; \ddots &amp; \vdots &amp; \vdots \\ \vdots &amp; \ddots &amp; \ddots &amp; 0 &amp; -a_{n-2} \\ 0 &amp; \cdots &amp; 0 &amp; 1 &amp; -a_{n-1}\end{pmatrix}\begin{pmatrix}x_1 \\ \vdots \\ x_n \end{pmatrix} + \begin{pmatrix}b_0 \\ \vdots \\ b_{n-1}\end{pmatrix}u, \\ y=\begin{pmatrix}0 &amp; \cdots &amp; 0 &amp; 1\end{pmatrix}+du\] <p>Between controllable canonical form and observable canonical form, following holds:</p> \[\begin{cases} \frac{dx(t)}{dt}=A_cx(t)+B_cu(t)\\ y(t)=C_cx(t)+D_cu(t)\end{cases}\] \[\begin{cases}\frac{dx(t)}{dt}=A_ox(t)+B_ou(t)\\ y(t)=C_ox(t)+D_ou(t)\end{cases}\] \[A_c^T=A_o, B_c^T=C_o, C_c^T=B_o, D_c^T=D_o\] <h3 id="state-space-representation-to-transfer-function">State-Space representation to Transfer function</h3> \[\begin{cases}\frac{dx}{dt}=Ax+Bu\\y=Cx+Du\end{cases}\rightarrow \begin{cases}sX=AX+BU\\Y=CX+DU\end{cases}\rightarrow G(s)=\frac{Y(s)}{U(s)}=C(sI-A)^{-1}B+D\] <h2 id="block-diagram-on-state-space-representation">Block diagram on State-Space representation</h2> <p>Two systems are given.</p> \[G_1:\begin{cases}\frac{dx_1}{dt}=A_1x_1+B_1u_1\\y_1=C_1x_1+D_1u_1\end{cases}, G_2:\begin{cases}\frac{dx_2}{dt}=A_2x_2+B_2u_2\\y_2=C_2x_2+D_2u_2\end{cases}\] <h3 id="cascade">Cascade</h3> <p>\(u=u_1, y_1=u_2, y=y_2\) lead to:</p> \[G:\begin{cases}\frac{dx}{dt}=\begin{pmatrix}A_1 &amp; 0\\B_2C_1 &amp; A_2\end{pmatrix}x+\begin{pmatrix}B_1\\B_2D_1\end{pmatrix}u\\y=\begin{pmatrix}D_2C_1&amp;C_2\end{pmatrix}x+D_2D_1u\end{cases}\] <h3 id="parallel">Parallel</h3> <p>\(u=u_1=u_2, y=y_1+y_2\) lead to:</p> \[G:\begin{cases}\frac{dx}{dt}=\begin{pmatrix}A_1 &amp; 0 \\ 0 &amp; A_2\end{pmatrix}x+\begin{pmatrix}B_1 \\ B_2\end{pmatrix}u\\y=\begin{pmatrix}C_1&amp;C_2\end{pmatrix}x+(D_1+D_2)u\end{cases}\] <h3 id="negative-feedback">Negative feedback</h3> <p>\(u=u_1=y_2, y=y_1=u_2\) lead to:</p> \[G:\begin{cases}\frac{dx}{dt}=\begin{pmatrix}A_1-B_1ED_2C_1 &amp; -B_1EC_2\\ B_2(I-D_1ED_2)C_1 &amp; A_2-B_2D_1EC_2\end{pmatrix}x + \begin{pmatrix}B_1E\\B_2D_1E\end{pmatrix}u \\y=\begin{pmatrix}(I-D_1ED_2)C_1 &amp; -D_1EC_2\end{pmatrix}x+D_1Eu\end{cases}\] <h1 id="lti-system">LTI system</h1> <h2 id="causality-time-invariance-linearity">Causality, Time-invariance, Linearity</h2> <h3 id="causality">Causality</h3> <p>An operator \(\mathbf{T}\) is said to be \(causal\) if \((\mathbf{T}f)_\tau=(\mathbf{T}f_\tau)_\tau, \forall\tau\ge0\) for an arbitrary \(f\), where</p> \[f_\tau(t)=\begin{cases}f(t) &amp; 0\le t\le\tau \\ 0 &amp; \tau&lt;t\end{cases}\] <h3 id="time-invariance">Time-invariance</h3> <p>An operator \(\mathbf{T}\) is said to be \(time-invariant\) if \(\mathbf{T}S_\tau=S_\tau\mathbf{T}, \forall\tau\in\mathbb{R}\) where \(S_\tau\) is a shift operator defined as \(S_\tau(f(t))\colon= f(t-\tau)\)</p> <h3 id="linearity">Linearity</h3> <p>Let \(y_1\) and \(y_2\) be the outputs of a state-space system corresponding to the inputs \(u_1\) and \(u_2\), respectively. The system is \(linear\) if \(\alpha y_1+\beta y_2\) is the output corresponding to the input \(\alpha u_1 + \beta u_2\)</p> <h2 id="similarity-transformation-bw-state-space-systems">Similarity transformation b/w state-space systems</h2> <p>There are various equivalent state-space equations for a given transfer function. They can be transformed from &amp; to each other through similarity transformation \(\tilde{x}\colon= Tx\)</p> <p>With similarity transformation \(T\), \(\tilde{A}=TAT^{-1}, \tilde{B}=TB, \tilde{C}=CT^{-1}, \tilde{D}=D\)</p> <h2 id="solution-to-state-space-representation">Solution to state-space representation</h2> \[\begin{cases} \dot{x}=Ax+Bu\\ y=Cx+Du \end{cases} \rightarrow \begin{cases} x(t)=e^{At}(x(0)+\int_0^te^{-A\tau}Bu(\tau)d\tau)\\ y(t)=Cx(t)+Du(t) \end{cases}\] <h1 id="stability-analysis-of-state-space-system">Stability analysis of state-space system</h1> <p>Given a space-state system, we can define two kinds of stability: Lyapunov stability and input-output stability.</p> <h2 id="lyapunov-stability">Lyapunov stability</h2> <p>In Lyapunov sense, we consider the effect of A matrix(or of initial condition) on stability. There can be four cases:</p> <ol> <li>The system is marginally stable if x(t) is uniformly bounded for all x(0).</li> <li>The system is asymptotically stable if x(t) converges to 0 for all x(0).</li> <li>The system is exponentially stable if there existss \(c,\lambda&gt;0\) such that \(||x(t)||\le ce^{-\lambda t}||x(0)||\) for all x(0).</li> <li>The systme is unstable if it is not marginally stable.</li> </ol> <h2 id="lyapunov-stability-theorem">Lyapunov stability theorem</h2> <p>The following conditions are all equivalent for an LTI system.</p> <ol> <li>The system is asymptotically stable.</li> <li>The system is exponentially stable.</li> <li>All the eigenvalues of A has strictly negative real parts.</li> <li>For every symmetric positive definite matrix \(Q\), there existss a unique positive definite solution \(P\) to the Lyapunov equation \(A^TP+PA=-Q\).</li> </ol> \[pf&gt;\] <p>1→3:</p> \[\begin{align*} x(t)=e^{At}x(0)\\ x(\infty)=e^{A\infty}x(0)=0\\ \rightarrow e^{A\infty}=Pe^{J\infty}P^{-1}=0\\ e^{J\infty}=0\\ \mathrm{all}\ Re\{\lambda\}&lt;0 \end{align*}\] <p>2→3: 2→1→3</p> <p>3→2:</p> \[\begin{align*} ||e^{Jt}|| &amp;\le|e^{\lambda_nt}|+|te^{\lambda_nt}|+\cdots|\frac{t^{n-1}}{(n-1)!}e^{\lambda_nt}|\\ &amp;\le|e^{\lambda_nt}|+|te^{\lambda_nt}|+\cdots|t^{n-1}e^{\lambda_nt}|\\ &amp;\le|e^{\lambda_nt}|(1+|t|+|t^2|+\cdots+|t^{n-1}|)\\ &amp;\le|e^{\lambda_nt}|\cdot n(1+t^{n-1})\\ &amp;=e^{-2\lambda t}\cdot n(1+t^{n-1})\\ &amp;\le c\cdot e^{-\lambda t}\\ \end{align*}\\ \rightarrow ||x(t)||\le||P||\cdot ||P^{-1}||\cdot C e^{-\lambda t}||x(0)||\] <p>3→1: 3→2→1</p> <p>2→4: Set \(P=\int_0^\infty e^{A^Tt}Qe^{At}dt\). \(P\) is well defined since \(||e^{A^Tt}Qe^{At}||\) exponentially decays. Then we first show that \(P\) is the solution to \(A^TP+PA=-Q\). \(A^TP+PA=\int_0^\infty(A^Te^{A^Tt}Qe^{At}+e^{A^Tt}Qe^{At}A)dt=\int_0^\infty(e^{A^Tt}Qe^{At})'dt=\lim_{t\rightarrow\infty}e^{A^Tt}Qe^{At}-Q=-Q\). Then we show the uniqueness of the solution \(P\). Let \(\bar{P}\) be another solution. Since \(A^T(P-\bar{P})+(P-\bar{P})A=0\), we get \(\frac{d}{dt}(e^{A^Tt}(P-\bar{P})e^{At})=A^Te^{A^Tt}(P-\bar{P})e^{At}+e^{A^Tt}(P-\bar{P})e^{At}A=0\) and therefore \(e^{A^Tt}(P-\bar{P})e^{At}=c=0\). Therefore \(P=\bar{P}\).</p> <p>4→2: Let \(v(t)=x^TPx\). Then \(\lambda\min(P)||x||^2\le v(t)\le \lambda\max(P)||x||^2\) (\(\lambda\min(P)&gt;0\) since \(P\) is positive definite). \(\dot{v}=\dot{x}^TPx+x^TP\dot{x}=(Ax)^TPx+x^TP(Ax)=x^T(A^TP+PA)x=-x^TQx\le -\lambda\min(Q)||x||^2\le -\frac{\lambda\min(Q)}{\lambda\max(P)}v=-\lambda v\). Therefore \(v\le e^{-\lambda t}v(0)\). \(\lambda\min(P)||x||^2\le v(t)\le e^{-\lambda t}v(0) \le e^{-\lambda t}\lambda \max (P)||x(0)||^2\), \(||x||^2\le\frac{\lambda\max(P)}{\lambda\min(P)}e^{-\lambda t}||x(0)||^2\). Exponentially stable by definition.</p> <h2 id="input-output-stability">Input-output stability</h2> <p>BIBO stable if exists \(c\) such that \(\sup_{0\le t &lt;\infty}||y(t)||\le c \sup_{0\le t &lt;\infty}||u(t)||\).</p> <p>The system is BIBO stable &lt;=&gt;</p> \[\int_0^\infty |g_{ij}(t)|dt&lt;\infty, Ce^{At}B=g\] \[pf&gt;\] <p>i) →: Suppose \(\int_0^\infty |g_{ij}(t)|dt=\infty\) for some i, j. Let \(\tilde{g}_{ij}(T, t)=Ce^{A(t-\tau)}B\). With input</p> \[u_T(\tau)=\begin{cases}+e_j &amp;&amp; \tilde{g}_{ij}(T,\tau)\ge0 \\ -e_j &amp;&amp; \tilde{g}_{ij}(T,\tau)&lt;0\end{cases}\] <p>\(y(T)=\int_0^T\tilde{g}_{ij}(T,\tau)u_T(\tau)d\tau+Du_T(T)\), \(y_i(T)=\int_0^T|g_i(\tau)|d\tau\pm d_i\) is unbounded, therefore not BIBO stable.</p> <p>ii) ←: Let</p> <p>\(\tilde{g}_{ij}(T, t)=Ce^{A(t-\tau)}B\).</p> \[\begin{align*} ||y(t)||&amp;\le\int_0^t||\tilde{g}(t,\tau)||||u(\tau)||d\tau+||D||||u(t)||\\ &amp;\le(\int_0^t||\tilde{g}(t,\tau)||d\tau+||D||)\sup_{0\le t &lt;\infty}||u(t)||\\ &amp;\le(\int_0^t\sum||\tilde{g}_{ij}(t,\tau)||d\tau+||D||)\sup_{0\le t &lt;\infty}||u(t)||\\ &amp;\le(\int_0^\infty\sum||g_{ij}(\tau)||d\tau+||D||)\sup_{0\le t &lt;\infty}||u(t)|| \end{align*}\] <h2 id="bibo-stable-if-exponentially-stable">BIBO stable if Exponentially stable</h2> \[\begin{align*} |g_{ij}(t)|&amp;=|C_ie^{At}B_j|\\ &amp;\le||C_i||||e^{At}B_j||\\ &amp;=||C_i||||e^{At}x(0)||\\ &amp;=||C_i||||x(t)||\\ &amp;\le Ce^{-\lambda t}||x(0)||,\\ \int_0^\infty |g_{ij}(t)|dt &amp;\le \int_0^\infty C e^{-\lambda t}||x(0)||dt \\ &amp;&lt; \infty \end{align*}\] <p>Therefore we just need to consider the Lyapunov stability.</p> <h1 id="controllability">Controllability</h1> <p>The pair (A,B) is controllable if there existss u(t) that moves x(t) from x(0) to any x(s).</p> <p>The following conditions are equivalent:</p> <ol> <li>The pair (A,B) is controllable.</li> <li>Controllability matrix \(U_c=(B \ AB \ \cdots A^{n-1}B)\) has rank n.</li> <li>Controllability gramian \(W_s \int_0^se^{At}BB^Te^{A^Tt}dt\) is nonsingular for any s.</li> </ol> \[pf&gt;\] <p>1→2:</p> <p>By Cayley-Hamilton theorem,</p> \[e^{At}=q_1(t)I+q_2(t)A+q_3(t)A^2+\cdots+q_n(t)A^{n-1}\] \[x(s)=e^{As}(x(0)+\int_0^se^{-A\tau}Bu(\tau)d\tau),\\ \rightarrow e^{-As}x(s)-x(0)=\int_0^se^{-A\tau}Bu(\tau)d\tau\\ =\int_0^s\sum_{i=1}^n q_i(-\tau)A^{i-1}Bu(\tau)d\tau\\ =\sum_{i=1}^n A^{i-1}Bh_i \\ =U_c\begin{pmatrix}h_1 \\ \vdots \\ h_n\end{pmatrix}\] <p>\(U_c\) should be rank n because \(e^{-As}x(s)-x(0)\) can be any \(x\in\mathbb{R}^n\).</p> <p>2→3: Suppose \(W_s\) is singular for some \(s\). ⇒ \(\exists x\not=0 \ s.t. W_sx=0\)</p> \[W_sx=0 \rightarrow x^TW_sx=\int_0^sx^Te^{At}BB^Te^{A^Tt}xdt=0, B^Te^{A^Tt}x=0 (0\le t \le s)\\ \rightarrow B^Tx=0, B^TA^Tx=0, \cdots B^T(A^T)^{n-1}x=0\\ \rightarrow \begin{pmatrix}B^T \\ B^TA^T \\ \vdots \\ B^T(A^T)^{n-1}\end{pmatrix}x=U_c^Tx=0\\ \therefore rank(U_c)&lt;n\\\] <p>proved by contradiction</p> <p>3→1: given \(s, x(s)=x_1, x(0)=x_0\),</p> \[u(t)=B^Te^{A^T(s-t)}W_s^{-1}(-e^{-As}x_0+x_1)\\ \begin{align*} x(s)&amp;=e^{As}(x(0)+\int_0^s e^{-A\tau}Bu(\tau)d\tau)\\ &amp;=e^{As}x_0+\int_0^se^{A(s-\tau)}BB^Te^{A^T(s-\tau)}W_s^{-1}(-e^{-As}x_0+x_1)d\tau\\ &amp;=e^{As}x_0+\int_0^se^{A(s-\tau)}BB^Te^{A^T(s-\tau)}d\tau W_s^{-1}(-e^{-As}x_0+x_1)\\ &amp;=e^{As}x_0+W_sW_s^{-1}(-e^{-As}x_0+x_1)\\ &amp;=e^{As}x_0-e^{-As}x_0+x_1\\ &amp;=x_1 \end{align*}\] <p>therefore controllable.</p> <h2 id="controllable-decomposition">Controllable decomposition</h2> <p>If \(rank(U_c)=r&lt;n\), the system is uncontrollable. Then existss a similarity transform \(T \ s.t. \ \tilde{A}=TAT^{-1}=\begin{pmatrix} \tilde{A_{11}} &amp; \tilde{A_{12}} \\ 0 &amp; \tilde{A_{22}}\end{pmatrix}, \tilde{B}=TB=\begin{pmatrix}\tilde{B_1} \\ 0\end{pmatrix}\) and \((\tilde{A_{11}}, \tilde{B_1})\) is controllable.</p> <p>Construct \(Q=(v_1 \ \cdots \ v_r \ v_{r+1} \ \cdots \ v_n)\) where \(v_1, v_2, \cdots, v_r\) are linearly independent columns of \(U_c\) and \(v_{r+1}, \cdots, v_n\) are vectors that make \(Q\) nonsingular. Then, \(T=Q^{-1}\).</p> \[AQ=AT^{-1}=A(v_1 \ \cdots v_r \ v_{r+1} \ \cdots \ v_n)=(Av_1 \ \cdots Av_{r} \ Av_{r+1} \ \cdots \ Av_n)\] <p>Here \(Av_1, Av_2, \cdots, Av_r\) can be expressed as linear combination of \(v_1, v_2, \cdots, v_r\) since columns of \(AU_c\) are linear combinations of \(v_1, v_2, \cdots, v_r\). Then</p> \[AT^{-1}=(v_1 \ \cdots \ v_r \ v_{r+1} \ \cdots \ v_n)\begin{pmatrix}\tilde{A_{11}} &amp; \tilde{A_{12}} \\ 0 &amp;\tilde{A_{22}}\end{pmatrix}=T^{-1}\begin{pmatrix}\tilde{A_{11}} &amp; \tilde{A_{12}} \\ 0 &amp;\tilde{A_{22}}\end{pmatrix}\\ B=(v_1 \ \cdots \ v_r)\tilde{B_1}=(v_1 \ \cdots \ v_r \ v_{r+1} \ \cdots \ v_n)\begin{pmatrix}\tilde{B_1}\\0\end{pmatrix}\\ \to \tilde{A}=TAT^{-1}, \tilde{B}=TB\] \[\begin{align*} TU_c&amp;=T(B \ AB \ \cdots \ A^{n-1}B)\\ &amp;=(TB \ TAT^{-1}TB \ \cdots \ (TAT^{-1})^{n-1}TB)\\ &amp;=\begin{pmatrix}\tilde{B_1} &amp; \tilde{A_{11}}\tilde{B_1} &amp; \cdots &amp; \tilde{A_{11}}^{n-1}\tilde{B_1} \\ 0 &amp; 0 &amp; \cdots &amp; 0\end{pmatrix} \end{align*}\] \[\begin{align*} rank(TU_c)&amp;=rank\begin{pmatrix}\tilde{B_1} &amp; \tilde{A_{11}}\tilde{B_1} &amp; \cdots &amp; \tilde{A_{11}}^{n-1}\tilde{B_1} \\ 0 &amp; 0 &amp; \cdots &amp; 0\end{pmatrix}\\ &amp;=rank\begin{pmatrix}\tilde{B_1} &amp; \tilde{A_{11}}\tilde{B_1} &amp; \cdots &amp; \tilde{A_{11}}^{n-1}\tilde{B_1}\end{pmatrix}\\ &amp;=rank(U_c)\\ &amp;=r \end{align*}\] <p>therefore \((\tilde{A_{11}}, \tilde{B_1})\) is controllable.</p> <h2 id="stabilizability-and-pbh-test">Stabilizability and PBH test</h2> <p>System is stabilizable if \(\tilde{A_{22}}\) is stable.</p> <p>PBH(Popov-Belevitch-Hautus) test gives equivalent condition on controllable and stabilizable.</p> <ol> <li>Pair \((A,B)\) is controllable iff \(rank(A-\lambda I \ B)=n, \ \forall\lambda \in \mathbb{C}\)</li> <li>Pair \((A,B)\) is stabilizable iff \(rank(A-\lambda I \ B)=n, \ \forall \lambda\in\mathbb{C}, Re\{\lambda\}\ge0\)</li> </ol> <p>pf of 1 → : Suppose \(\exists\lambda \ s.t. \ rank(A-\lambda I \ B)&lt;n\).</p> \[\exists v\not=0 \ s.t. v^T(A-\lambda I \ B)=0\] \[v^TA=\lambda v^T, \ v^TB=0 \\ \to v^TA^l=\lambda^l v^T, v^TA^lB=\lambda^l v^TB=0\\ \to v^T(B \ AB \ \cdots \ A^{n-1}B)=0\] <p>\((A,B)\) is not controllable.</p> <p>pf of 1 ← : Suppose \((A,B)\) is not controllable.</p> <p>Do controllable decomposition \(\tilde{A}=\begin{pmatrix}\tilde{A_{11}} &amp; \tilde{A_{12}} \\ 0 &amp; \tilde{A_{22}}\end{pmatrix}, \tilde{B}=\begin{pmatrix}\tilde{B_1}\\ 0\end{pmatrix}\), let \(\lambda, v\) be eigenvalue of \(\tilde{A_{22}}\) and corresponding eigenvector, where \(Re\{\lambda\}\ge0\). Then \((\tilde{A}-\lambda I \ \tilde{B})\begin{pmatrix}0 \\ v\end{pmatrix}=\begin{pmatrix}\tilde{A_{11}}-\lambda I &amp; \tilde{A} &amp; \tilde{B_1} \\ 0 &amp; \tilde{A_{22}}-\lambda I &amp; 0\end{pmatrix}\begin{pmatrix}0 \\ v\end{pmatrix}=0\) therefore \(rank(\tilde{A}-\lambda I \ \tilde B)&lt;n\). \(rank(A-\lambda I \ B)=rank(T^{-1}(A-\lambda I \ B)\begin{pmatrix}T &amp; 0 \\ 0 &amp; I\end{pmatrix})=rank(\tilde A - \lambda I \ \tilde B)&lt;n\)</p> <p>pf of 2 → : Suppose \(\exists \lambda \ s.t. \ Re\{\lambda\}\ge 0\) and \(rank(A-\lambda I \ B)&lt;n\).</p> \[rank(A-\lambda I \ B)=rank(\tilde A -\lambda I \ \tilde B)&lt;n \to \exists v=\begin{pmatrix}v_1 \\ v_2\end{pmatrix}\not=0 \ s.t. v^T(\tilde A -\lambda I \ \tilde B)=0\] \[v_1^T\tilde A_{11}=\lambda v_1^T, v_1^T\tilde B_1=0, v_1^T\tilde A_{12}+v_2^T\tilde A_{22}=\lambda v_2^T\] <p>since \((\tilde A_{11}, \tilde B_1)\) is controllable, \(v_1=0\) therefore \(v_2^T\tilde A_{22}=\lambda v_2^T\)</p> <p>\(\lambda\) is eigenvalue of \(\tilde A_{22} \to\) system is not stabilizable.</p> <p>pf of 2 ← : Suppose not stabilizable.</p> \[rank(A-\lambda I \ B)=rank(\tilde A -\lambda I \ \tilde B) = rank\begin{pmatrix}\tilde A_{11}-\lambda I &amp; \tilde A_{12} &amp; \tilde B_1 \\ 0 &amp; \tilde A_{22}-\lambda I &amp; 0 \end{pmatrix}&lt;n\] <h1 id="observability">Observability</h1> <p>The pair (C, A) is observable if we can uniquely determine initial state using y(t) and u(t).</p> <p>The following conditions are equivalent.</p> <ol> <li>The pair (C, A) is observable.</li> <li>Observability matrix \(U_o=\begin{pmatrix}C \\\ CA \\\ \vdots \\\ C(A)^{n-1}\end{pmatrix}\) has rank n</li> <li>Observability gramian \(Y_s=\int_0^se^{A^Tt}C^TCe^{At}dt\) is nonsinular</li> </ol> \[pf&gt;\] <p>1→2: Suppose \(rank(U_o)&lt;n \to \exists x_0\not=0 \ s.t. \ U_ox_0=0\).</p> \[Cx_0=0, CAx_0=0, \cdots, CA^{n-1}x_0=0 \to Ce^{At}x_0=0\\ \begin{align*} y(t)&amp;=Ce^{At}x_0+\int_0^tCe^{A(t-\tau)}Bu(\tau)d\tau+Du(t)\\ &amp;=\int_0^tCe^{A(t-\tau)}Bu(\tau)d\tau+Du(t) \end{align*}\] <p>cannot determine \(x(0)\to\)not observable.</p> <p>2→3: Suppose \(Y_s\) is singular \(\to \exists v\not=0 \ s.t. \ Y_sv=0\)</p> \[v^TY_sv=0 \to Ce^{At}v=0, \ \therefore Cv=CAv=\cdots=CA^{n-1}v=0\to U_o v=0 \to rank(U_o)&lt;n\] <p>3→1:</p> \[\begin{align*} x_0&amp;=Y_s^{-1}Y_sx_0\\ &amp;=Y_s^{-1}\int_0^se^{A^Tt}C^TCe^{At}dsx_0\\ &amp;=Y_s^{-1}\int_0^se^{A^Tt}C^T(y(t)-Ce^{At}\int_0^te^{-A\tau}Bu(\tau)d\tau)dt \end{align*}\] <p>therefore observable</p> <h2 id="observable-decomposition">Observable decomposition</h2> <p>If \(rank(U_o)=r&lt;n\), the system is unobservable. Then existss a similarity transform \(T \ s.t. \ \tilde{A}=TAT^{-1}=\begin{pmatrix} \tilde A_{11} &amp; 0 \\ \tilde A_{21} &amp; \tilde A_{22} \end{pmatrix}, \tilde{C}=CT^{-1}=\begin{pmatrix}\tilde{C_1} &amp; 0\end{pmatrix}\) and \((\tilde C_1, \tilde A_{11})\) is observable.</p> <p>Construct \(T=\begin{pmatrix}w_1 \\ \vdots \\ w_r \\ w_{r+1} \\ \vdots \\ w_n\end{pmatrix}\) where \(w_1, \cdots, w_r\) are linearly independent rows of \(U_o\) and \(w_{r+1}, \cdots, w_n\) are lineary independent vectors that make \(T\) nonsingular.</p> <p>In the same way as controllable decomposition,</p> \[TA=\begin{pmatrix}w_1 \\ \vdots \\ w_r \\ w_{r+1} \\ \vdots \\ w_n\end{pmatrix}A=\begin{pmatrix}w_1A \\ \vdots \\ w_rA \\ w_{r+1}A \\ \vdots \\ w_nA\end{pmatrix}=\begin{pmatrix}\tilde A_{11} &amp; 0 \\ \tilde A_{21} &amp; \tilde A_{22}\end{pmatrix}\begin{pmatrix}w_1 \\ \vdots \\ w_r \\ w_{r+1} \\ \vdots \\ w_n\end{pmatrix}=\begin{pmatrix}\tilde A_{11} &amp; 0 \\ \tilde A_{21} &amp; \tilde A_{22}\end{pmatrix}T\\ C=\tilde C_1 \begin{pmatrix}w_1 \\ \vdots \\ w_r\end{pmatrix}=(\tilde C_1 \ 0)\begin{pmatrix}w_1 \\ \vdots \\ w_r \\ w_{r+1} \\ \vdots \\ w_n\end{pmatrix}=(\tilde C_1 \ 0)T\] \[U_oT^{-1}=\begin{pmatrix}C \\ CA \\ \vdots \\ CA^{n-1}\end{pmatrix}T^{-1}=\begin{pmatrix}CT^{-1} \\ CT^{-1}TAT^{-1} \\ \vdots \\ CT^{-1}(TAT^{-1})^{n-1}\end{pmatrix}=\begin{pmatrix}\tilde C_1 &amp; 0 \\ \tilde C_1 \tilde A_{11} &amp; 0 \\ \vdots &amp; \vdots\\ \tilde C_1 \tilde A_{11}^{n-1} &amp; 0\end{pmatrix}\\ rank(U_oT^{-1})=rank\begin{pmatrix}\tilde C_1 \\ \tilde C_1 \tilde A_{11}\\ \vdots \\ \tilde C_1 \tilde A_{11}^{n-1}\end{pmatrix}=r\] <p>\((\tilde C_1, \tilde A_{11})\) is observable</p> <h2 id="detectability-and-pbh-test">Detectability and PBH test</h2> <p>Detectable if \(\tilde A_{22}\) is stable.</p> <ol> <li>\((C, A)\) is observable iff \(rank\begin{pmatrix}A-\lambda I \\ C\end{pmatrix}=n, \forall \lambda\in\mathbb{C}\)</li> <li>\((C,A)\) is detectable iff \(rank\begin{pmatrix}A-\lambda I \\ C\end{pmatrix}=n, \forall \lambda\in\mathbb{C}, Re\{\lambda\}\ge0\)</li> </ol> <p>pf&gt; Can be easily shown</p> <h1 id="state-feedback-controller">State feedback controller</h1> <p>Given state-space model \(\begin{cases} \frac{dx}{dt}=Ax+Bu\\ y=Cx+Du \end{cases}\)의 시스템 특성을 조절하기 위해서는, controllable canonical form으로 바꾼 후에 pole location을 하면 된다.</p> <ol> <li> <p>Similarity transform \(T\ s.t. \ A_c=TAT^{-1}\)</p> <p>\(U_c^{-1}=\begin{pmatrix}*\\\ q \end{pmatrix} \to T=\begin{pmatrix}q \\\ qA \\\ \vdots \\\ qA^{n-1}\end{pmatrix}\) makes \(TAT^{-1}=A_c\) and \(TB = B_c\).</p> </li> <li> <p>Pole location</p> <p>When we do state feedback (u=r+Fx), matrix A becomes \(A+BF\). For canonical form, \(A_c+B_cF_c=\begin{pmatrix}0 &amp; 1 &amp; 0 &amp; \cdots &amp; 0 \\\ 0 &amp; 0 &amp; 1 &amp; \cdots &amp; 0 \\\ \vdots &amp; \ddots &amp; \ddots &amp; \ddots &amp; \vdots \\\ 0 &amp; \cdots &amp; \cdots &amp; \cdots &amp; 1 \\\ -\alpha_0+f_0 &amp; -\alpha_1+f_1 &amp; \cdots &amp; \cdots &amp; -\alpha_{n-1}+f_{n-1}\end{pmatrix}\) where \(F_c=(f_0 \ f_1 \ \cdots \ f_{n-1})\).</p> <p>Since \(|sI-(A_c+B_cF_c)|=s^n+(\alpha_{n-1}-f_{n-1})s^{n-1}+\cdots+(\alpha_0-f_0)\), we can assign arbitrary eigenvalues of \(A_c+B_cF_c\).</p> </li> <li> <p>Return to original model</p> <p>When we find \(F_c\), return to \(F=F_cT\)</p> </li> </ol> <p>Can assign eigenvalues of \(A+BF \ iff \ (A,B)\) is controllable.</p> <h1 id="state-observer">State observer</h1> <p>Given state-space model \(\begin{cases} \frac{dx}{dt}=Ax+Bu\\ y=Cx+Du \end{cases}\)</p> <p>State observer \(\begin{cases} \frac{d\hat{x}}{dt}=A\hat{x}-K(y-\hat{y})+Bu\\ \hat{y}=C\hat{x}+Du \end{cases}\)</p> <p>Then, \(e=x-\hat{x}\)</p> \[\begin{align*} \dot{e}&amp;=\dot{x}-\dot{\hat{x}}\\ &amp;=Ax+Bu-(A\hat{x}+Bu-K(y-\hat{y}))\\ &amp;=A(x-\hat{x})+K(y-\hat{y})\\ &amp;=A(x-\hat{x})+KC(x-\hat{x})\\ &amp;=(A+KC)(x-\hat{x})\\ &amp;=(A+KC)e \end{align*}\\ \to e(t)=e^{(A+KC)t}e(0)\] <p>If \((A+KC)\) is exponentially stable, \(e(t)\to0\) as \(t \to \infty\) which means we can accruately estimate real state value \(x\) for any initial guess.</p> <p>We can arbitrary assign poles of \(A+KC \ iff \ (C,A)\) is observable since \(\lambda(A+KC)=\lambda(A^T+C^TK^T)\) and \((C,A)\) is observable iff \((A^T, C^T)\) is controllable.</p>]]></content><author><name></name></author><category term="[&quot;Notes&quot;]"/><category term="Control theory"/><summary type="html"><![CDATA[현대제어에서는 state-space model을 구성하고 시스템을 분석한다.]]></summary></entry><entry xml:lang="ko"><title type="html">Classical Control Theory</title><link href="https://hsjung02.github.io/blog/2022/Classical-Control-Theory/" rel="alternate" type="text/html" title="Classical Control Theory"/><published>2022-12-20T00:05:42+00:00</published><updated>2022-12-20T00:05:42+00:00</updated><id>https://hsjung02.github.io/blog/2022/Classical-Control-Theory</id><content type="html" xml:base="https://hsjung02.github.io/blog/2022/Classical-Control-Theory/"><![CDATA[<h1 id="lti-system">LTI System</h1> <p>LTI system이란 (1) Linear하고, (2) Time-Invariant한 시스템이다. Linear system은 additivity와 homogeneity가 성립하는 시스템을 뜻한다. Time-Invariant란 입력 신호의 time shift가 출력 신호에 그대로 반영되는 시스템 특성을 의미한다. Time-Invariant system은 시간이 흘러도 시스템 특성이 변하지 않는다.</p> <h1 id="convolution-integral">Convolution Integral</h1> <p>신호 및 시스템 수업에서 배운 것처럼, 어떤 시간 t에서의 입력 신호는 t 이후의 모든 시간에서의 출력 신호에 영향을 줄 수 있다. 따라서 출력은 입력과 impulse response의 convolution integral로 나타낼 수 있다.</p> <h1 id="laplace-transform">Laplace Transform</h1> <p>Convolution integral은 대수적으로 풀기 어렵기 때문에, time-domain에서 convolution integral을 풀기보다는 Laplace transform을 통해 s-domain에서 두 함수의 대수곱으로 변형하여 푼다.</p> <p>Laplace Transform은 다음과 같이 정의할 수 있다.</p> \[\mathscr{L} \{ f(t)\}(s)=\int_{0-}^{\infty}f(t)e^{-st}dt\] <p>Laplace Transform은 f(t)에서 주파수 s인 신호의 진폭과 위상을 얻는 방법이다. Fouries Transform은 s=jw인 Laplace Transform의 특수한 경우이다.</p> <p>Laplace Transform은 time-domain에서의 컨볼루션 곱을 s-domain에서의 대수곱으로 변형할 수 있다.</p> \[\mathscr{L}\{f(t)*g(t)\}(s)=\mathscr{L}\{f(t)\}\cdot\mathscr{L}\{g(t)\}\] <h2 id="obtaining-system-response">Obtaining System Response</h2> <p>시스템 응답을 얻는 과정은 다음과 같다.</p> <ol> <li>전달함수 H(s)를 구한다. \(H(s)=\mathscr{L}\{h(t)\}(s)\), h(t): impulse response</li> <li>입력 신호 U(s)를 결정한다.</li> <li>출력 신호를 구한다. \(Y(s)=H(s)U(s)\)</li> <li>Time-domain에서의 출력을 구한다. \(y(t)=\mathscr{L}^{-1}\{Y(s)\}\)</li> </ol> <h1 id="transfer-function">Transfer Function</h1> <p>Transfer function이란 s-domain에서 입력 신호와 출력 신호의 비이다. Time-domain differential equation으로부터 구할 수도 있고, impulse response를 Laplace Transform하여 구할 수도 있다.</p> <p>Linear system의 Transfer function은 분모의 차수가 분자의 차수보다 크거나 같은 유리함수로 나타나며, 현실 세계에 존재하는 시스템에 대한 transfer function은 모두 실수 계수를 가진다.</p> <p>Transfer function을 통해 시스템의 특성을 파악할 수 있는데, 가장 먼저 알아야 할 것이 바로 pole과 zero이다. Pole은 분모를 0으로 만드는 s 값을, Zero는 분자를 0으로 만드는 s 값을 의미한다.</p> <p>주어진 Transfer function은 다음과 같이 인수분해할 수 있다. \(H(s)=K\frac{\prod_{i=1}^m(s-z_{i})}{\prod_{i=1}^n(s-p_{i})}\). \(p_i\)는 pole을, \(z_{i}\)는 zero를 나타낸다. 만약 \(p_{i}=z_{j}\)인 i, j가 존재한다면 약분해야만 시스템 응답을 제대로 분석할 수 있는데, 우리는 그러한 i, j가 존재하지 않는다고 가정한다. 모델링의 관점에서 보면, \(p_{i}=z_{j}\)인 i, j가 존재하더라도 실제로는 \(p_{i}\not=z_{j}\)임에도 모델링 오차에 의해 pole-zero cancellation을 진행하면 시스템 응답을 제대로 분석할 수 없기 때문이다. 물론 pole에 가까운 zero는 그 pole의 영향을 줄이는 효과가 있지만 응답에 오차가 생기는 것은 사실이다.</p> <p>아래에서 보겠지만 zero보다는 pole이 응답에 더 큰 영향을 미친다. 특히 s-plane에서 pole이 imaginary axis 상에 있다면 neutral stable하고 pole이 ORHP에 있다면 시스템 응답이 발산하기에, 우리는 pole이 OLHP상에 있는 상황을 가정한다.</p> <p>\(s=-\sigma\pm j\omega_{d}\)를 pole로 가지는 second-order transfer function을 고려하자.</p> <p>\(H(s)=\frac{\sigma^{2}+\omega_{d}^{2}}{(s+\sigma)^{2}+\omega_{d}^{2}}\), \(\omega_{n}^{2}=\omega_{d}^{2}+\sigma^{2}, \zeta=\tan^{-1}\left(\frac{\sigma}{\omega_{n}}\right)\)로 정의하면</p> <p>\(H(s)=\frac{\omega_{n}^{2}}{s^{2}+2\zeta\omega_{n}+\omega_{n}^{2}}\)으로 쓸 수 있고, 식을 풀면 \(h(t)=1-e^{-\zeta\omega_{n}t}\left(\cos\omega_{d}t+\frac{\sigma}{\omega_{d}}\sin\omega_{d}t\right)\)로 쓸 수 있다. 여기서 \(\zeta\)를 damping ratio라 하고, 감쇠/진동의 정도를 나타낸다. h(t)에서 exponential term이 감쇠항, cos &amp; sin term이 진동항이다. damping ratio가 클수록 감쇠의 정도가 심하다.</p> <h2 id="block-diagram">Block Diagram</h2> <p>대부분의 시스템은 그것을 구성하는 서브시스템으로 분할할 수 있는데, 이때 각 서브시스템의 요소들은 서로에게 영향을 주지 않는다. 대신, 한 서브시스템의 출력이 다른 서브시스템의 입력으로 사용되고는 한다. 이 관계를 도식화하기 위한 툴이 바로 block diagram이다. Block diagram을 보면 전달함수를 쉽게 구할 수 있다.</p> <p><img src="/assets/img/posts/Classical-Control-Theory/Untitled.png" alt="Untitled"/></p> <h2 id="inverse-laplace-transform-by-partial-fraction-expansion">Inverse Laplace Transform by partial fraction expansion</h2> <p>유리함수로 주어진 Laplace Transform은 partial fraction expansion과 inverse Laplace transform을 통해 time-domain 신호로 변환할 수 있다.</p> <p>왜냐하면 우리는 \(\frac{1}{s+a}\)꼴과 \(\frac{as+b}{(s+c)^{2}+d^{2}}\)꼴의 inverse Laplace transform을 알고 있기 때문이다.</p> <p>따라서 \(H(s)=K\frac{\prod_{i=1}^m(s-z_{i})}{\prod_{i=1}^n(s-p_{i})}=\sum_{i=1}^n\frac{k_{i}}{s-p_{i}}\)로 partial fraction expansion하여 inverse Laplace transform하면 h(t)를 구할 수 있다.</p> <h2 id="initial-value-theorem--final-value-theorem">Initial Value Theorem &amp; Final Value Theorem</h2> <p>라플라스 변환을 활용하면 time-domain에서의 초기값과 정상 상태에서의 값을 알 수 있다.</p> <p>Initial Value Theorem: \(\lim_{t\to0} y(t)=\lim_{s\to\infty}sY(s)\)</p> <p>Final Value Theorem: When all poles of \(sY(s)\) are on OLHP, \(\lim_{t\to\infty} y(t)=\lim_{s\to0}sY(s)\)</p> <h1 id="time-domain-specification">Time-domain Specification</h1> <p>Laplace transform을 통해 frequency response를 분석하지만, 결국 우리는 time-domain에 살고 있고 제어 또한 time-domain에서 이루어진다. 따라서 우리는 출력 신호가 time-domain에서 어떠한 응답을 가지는지 파악할 필요가 있고, 이때 사용하는 지표들이 time-domain specification이다. 대표적인 time-domain spec으로는 rise time, settling time, peak time, overshoot이 있다. 아래에는 각 spec의 정의와 second-order transfer function \(H(s)=\frac{\omega_{n}^{2}}{s^{2}+2\zeta\omega_{n}+\omega_{n}^{2}}\)에서 각 spec들을 근사적으로 구하는 방법을 소개한다.</p> <h2 id="rise-time">Rise time</h2> <p>Rise time은 신호가 목표값의 10%~90% 구간에 머무는 시간을 의미하며, \(t_r\)로 쓴다. \(t_{r}\approx\frac{1.8}{\omega_n}\)이다.</p> <h2 id="settling-time">Settling time</h2> <p>Settling time은 신호의 오차가 1% 이내로 유지되는 최단시간을 의미하며, \(t_s\)로 쓴다. \(t_{s}=\frac{4.6}{\sigma}\)이다.</p> <h2 id="peak-time">Peak time</h2> <p>Peak time은 신호가 첫 피크에 도달하는 시간을 의미하며, \(t_p\)로 쓴다. \(t_{p}=\frac{\pi}{\omega_{d}}\)이다.</p> <h2 id="overshoot">Overshoot</h2> <p>Overshoot은 최대 상대오차를 의미하며, \(M_p\)로 쓴다. \(M_{p}=e^{-\frac{\pi\zeta}{\sqrt{1-\zeta^{2}}}}\)이다.</p> <h1 id="stability-and-location-of-poles">Stability and Location of Poles</h1> <p>A LTI System is stable ↔ All poles are on OLHP</p> <p>Poles on RHP make the system response diverge!</p> <h2 id="bibo-stability">BIBO Stability</h2> <p>The system is BIBO stable: Bounded Input always makes a Bounded Output</p> <p>The system is BIBO stable \(\Longleftrightarrow \int_{-\infty}^{\infty} |h(t)|dt &lt;\infty\)</p> <p>Proof</p> <p>(i) ←:</p> \[|y(t)|=|\int_{-\infty}^{\infty}u(\tau)h(t-\tau)d\tau|\le \int_{-\infty}^{\infty}|u(\tau)h(t-\tau)|d\tau\le M\int_{-\infty}^{\infty}|h(t)|dt\] <p>(ii) →:</p> <p>The statement is equal to: If \(\int_{-\infty}^{\infty} |h(t)|dt\) diverges, the system is not BIBO stable</p> <p>Let \(u(t)=\begin{cases}1 &amp;&amp; \text{if }h(t)&gt;0 \\ -1 &amp;&amp; \text{otherwise}\end{cases}\) then \(|y(t)|=|\int_{-\infty}^{\infty}u(\tau)h(t-\tau)d\tau|=|\int_{-\infty}^{\infty}|h(t-\tau)|d\tau|\) diverges, so the system is not BIBO stable</p> <h2 id="routh-criterion">Routh Criterion</h2> <p>A LTI System is stable ↔ Every components in the first column of the Routh array is positive</p> <h3 id="what-is-the-routh-array">What is the Routh Array?</h3> <p>Routh array is defined as:</p> \[\begin{pmatrix} 1 &amp;&amp; a_{2} &amp;&amp; a_{4} &amp;&amp; \cdots \\ a_{1} &amp;&amp; a_{3} &amp;&amp; a_{5} &amp;&amp; \cdots \\ b_{1} &amp;&amp; b_{2} &amp;&amp; b_{3} &amp;&amp; \cdots \\ c_{1} &amp;&amp; c_{2} &amp;&amp; c_{3} &amp;&amp; \cdots \\ \vdots &amp;&amp; \vdots &amp;&amp; \vdots &amp;&amp; \\ * &amp;&amp; * \\ * \\ *\end{pmatrix}\] \[b_{1}=-\frac{\text{det}\begin{bmatrix}1 &amp;&amp; a_{2} \\ a_{1} &amp;&amp; a_{3}\end{bmatrix}}{a_1}=\frac{a_{1}a_{2}-a_{3}}{a_{1}} \\ b_{2}=-\frac{\text{det}\begin{bmatrix}1 &amp;&amp; a_{4} \\ a_{1} &amp;&amp; a_{5}\end{bmatrix}}{a_1}=\frac{a_{1}a_{4}-a_{5}}{a_{1}} \\ b_{3}=-\frac{\text{det}\begin{bmatrix}1 &amp;&amp; a_{6} \\ a_{1} &amp;&amp; a_{7}\end{bmatrix}}{a_1}=\frac{a_{1}a_{6}-a_{7}}{a_{1}} \\ c_{1}=-\frac{\text{det}\begin{bmatrix}a_{1} &amp;&amp; a_{3} \\ b_{1} &amp;&amp; b_{2}\end{bmatrix}}{b_1}=\frac{b_{1}a_{3}-a_{1}b_{2}}{b_{1}} \\ c_{2}=-\frac{\text{det}\begin{bmatrix}a_{1} &amp;&amp; a_{5} \\ b_{1} &amp;&amp; b_{3}\end{bmatrix}}{b_1}=\frac{b_{1}a_{5}-a_{1}b_{3}}{b_{1}} \\ c_{3}=-\frac{\text{det}\begin{bmatrix}a_{1} &amp;&amp; a_{7} \\ b_{1} &amp;&amp; b_{4}\end{bmatrix}}{b_1}=\frac{b_{1}a_{7}-a_{1}b_{4}}{b_1} \\\] <p>We can expand the array in the same way.</p> <p>The number of sign changes in the first column of the Routh array is equal to the number of poles on the RHP. Since the first component of the first column is positive(1), the first column should be positive.</p> <h1 id="closed-loop-system-analysis">Closed-loop system analysis</h1> <p><img src="/assets/img/posts/Classical-Control-Theory/Untitled%201.png" alt="Untitled"/></p> \[Y = GDR + GW\] \[E = (1-GD)R-GW\] <p><img src="/assets/img/posts/Classical-Control-Theory/Untitled%202.png" alt="Untitled"/></p> \[Y = \frac{GD}{1+GD}R+\frac{G}{1+GD}W-\frac{GD}{1+GD}V\] \[E = \frac{1}{1+GD}R-\frac{G}{1+GD}W+\frac{GD}{1+GD}V\] <h2 id="sensitivity">Sensitivity</h2> <p>By some modeling error or environment change, plant G can change and thus transfer function T changes.</p> \[S = \frac{\text{fractional change in }T}{\text{fractional change in }G} = \frac{\frac{\delta T}{T}}{\frac{\delta G}{G}}\] <p>The system is robust when its sensitivity is low.</p> <p>Sensitivity of open-loop system:</p> \[T+\delta T = D(G+\delta G) = DG +D\delta G=T+D\delta G\] \[\delta T = D \delta G, \frac{\delta T}{T}=\frac{D\delta G}{DG}=\frac{\delta G}{G}\] \[S = \frac{\frac{\delta T}{T}}{\frac{\delta G}{G}}=1\] <p>Sensitivity of closed-loop system:</p> <p>using 1st-order approximation, \(\delta T =\frac{dT}{dG}\delta G\)</p> \[S =\frac{\frac{\delta T}{T}}{\frac{\delta G}{G}}=\frac{G}{T}\frac{\delta T}{\delta G}=\frac{G}{T}\frac{dT}{dG}=\frac{1}{1+GD}\] <h2 id="system-type">System Type</h2> <p>Every inputs can be considered as polynomial inputs(according to Taylor expansion), and system with higher system type is able to maintain low steady-state error for high degree polynomial input.</p> <p>System with system type n makes zero steady-state error for polynomial inputs with degree lower than n, nonzero finite steady-state error for polynomial inputs with degree n, infinite error for polynomial inputs with degree higher than n.</p> <h3 id="system-type-for-reference-tracking">System type for reference tracking</h3> \[E = \frac{1}{1+GD}R\] <p>System type n = number of poles of GD at the origin(s=0)</p> <h3 id="system-type-for-disturbance-rejection">System type for disturbance rejection</h3> \[E = -\frac{G}{1+GD}W\] <p>System type n = number of zeros of G/(1+GD) at the origin(s=0)</p> <h1 id="pid-control">PID Control</h1> \[u(t) = k_p e(t)+k_I\int_{t_0}^te(\tau)d\tau+k_D\frac{d}{dt}e(t)\] \[D(s)=k_p+\frac{k_I}{s}+k_Ds\] <h1 id="characteristic-equation-of-feedback-system">Characteristic Equation of feedback system</h1> <p><img src="/assets/img/posts/Classical-Control-Theory/Untitled%203.png" alt="Untitled"/></p> \[T(s)=\frac{DG}{1+DGH}\] <p>Characteristic equation: \(1+D(s)G(s)H(s)=0\)→\(a(s)+Kb(s)=0\)→\(1+KL(s)=0\)</p> <p>Pole of transfer function is a function of parameter \(K\)</p> <h1 id="what-is-root-locus">What is Root Locus?</h1> <p>Root Locus is plot of the locus of all possible roots of \(1+KL(s)=0\) as \(K\) varies from \(0\) to \(\inf\)</p> <p>How to draw the locus?</p> <p>Just consider the rules.</p> <p>\(L(s)=\frac{b(s)}{a(s)}\) and \(b(s)\), \(a(s)\) are monic polynomials with degree \(n,m (n\ge m)\)</p> <h2 id="rule-1">Rule 1</h2> <p>The \(n\) branches of the locus start at the poles of \(L(s)\) and \(m\) of these branches end on the zeros of \(L(s)\)</p> <h2 id="rule-2">Rule 2</h2> <p>The loci are on the real axis to the left of an odd number of poles and zeros</p> <h2 id="rule-3">Rule 3</h2> <p>For large \(s\) and \(K\), \(n-m\) of the loci are asymptotic to the lines at angles \(\phi_l\) radiating out from the points \(s=\alpha\) on the real axis where</p> <p>(angles of asymptotes) \(\phi_l = \frac{180^\circ+360^\circ (l-1)}{n-m}, l=1,2,\cdots,n-m\)</p> <p>(center of asymptotes) \(\alpha = \frac{\sum p_i -\sum z_i}{n-m}\)</p> <h2 id="rule-4">Rule 4</h2> <p>Angle of departure from a pole \(p_j\) of multiplicity \(q\):</p> \[q\phi_{l, \text{dep}}=\sum \psi_i-\sum \phi_i -180^\circ -360^\circ(l-1)\] \[\psi_i = \angle(p_j-z_i), \phi_i = \angle(p_j-p_i)\] <p>Angle of arrival at a zero \(z_j\) of multiplicity \(q\):</p> \[q\psi_{l, \text{arr}}=\sum \phi_i-\sum \psi_i +180^\circ +360^\circ(l-1)\] \[\psi_i = \angle(z_j-z_i), \phi_i = \angle(z_j-p_i)\] <h2 id="rule-5">Rule 5</h2> <p>The locus crosses the \(j\omega\) axis where the Routh criterion shows a transition from roots in the LHP to the roots in RHP.</p> <p>If \(n-m&gt;2\), at least one branch of the locus crosses the imaginary axis.</p> <h2 id="rule-6">Rule 6</h2> <p>The locus has multiple roots at a point on the locus only if \(b\frac{da}{ds}-a\frac{db}{ds}=0\)</p> <h1 id="argument-principle">Argument Principle</h1> <p>A contour map of a complex function will encircle encircle the origin \(Z-P\) times clockwise, where \(Z\) is the number of zeros and \(P\) is the number of poles of the function inside the contour.</p> <h1 id="nyquist-stability-criterion">Nyquist Stability Criterion</h1> <p>By setting RHP as the contour, we can analyze stability of system with transfer function \(T(s) = \frac{KG(s)}{1+KG(s)}\)</p> <p>We have \(Z=N+P\) where</p> <p>\(Z\): the number of RHP poles of closed-loop system</p> <p>\(N\): the number of clockwise encirclement of \(KG(s)\) about -1</p> <p>\(P\): the number of RHP poles of open-loop system</p> <h1 id="nyquist-plot">Nyquist Plot</h1> <p>How to plot the Nyquist plot?</p> <ol> <li>Plot \(KG(s)\) for the contour, which is a half circle with infinitely large radius <ol> <li>Plot \(KG(s)\) for \(-j\infty \le s \le +j\infty\) (this can be done easily using Bode plot)</li> <li>If \(KG(s)=0\) at the origin, plot \(KG(s)\) for \(s=re^{j\theta}, (r=0, -\frac{\pi}{2}\le\theta\le\frac{\pi}{2})\)</li> <li>Plot \(KG(s)\) for \(s=re^{j\theta}, (r=\infty, -\frac{\pi}{2}\le\theta\le\frac{\pi}{2})\)</li> </ol> </li> <li>Evaluate the number of clockwise encirclement of -1 (=\(N\))</li> <li>Determine \(P\)</li> <li>\(Z=N+P\) and if \(Z=0\) the system is stable</li> </ol> <h1 id="gain-margin-and-phase-margin">Gain Margin and Phase Margin</h1> <h2 id="gain-margin">Gain Margin</h2> <p>the factor by which the gain can be raised before instability results</p> \[GM =K^*/K\] <h2 id="phase-margin">Phase Margin</h2> <p>the amount by which the phase of \(G(j\omega)\) exceeds -180 deg when \(|KG(j\omega)|=1\)</p> \[PM = \angle(KG(j\omega))-180 ^\circ\]]]></content><author><name></name></author><category term="[&quot;Notes&quot;]"/><category term="Control theory"/><summary type="html"><![CDATA[고전제어에서는 주파수 응답을 이용해 시스템 특성 파악 및 제어기 설계를 한다]]></summary></entry></feed>